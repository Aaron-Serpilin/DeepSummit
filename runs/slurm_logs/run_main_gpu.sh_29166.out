torch version: 2.0.1
torchvision version: 0.15.2
mlxtend version: 0.23.4
numpy version: 2.0.1
Device is: cpu

[INFO] Data splits already exist under data/himalayas_data. Skipping split.
Tabular train dataloader: <torch.utils.data.dataloader.DataLoader object at 0x7fc6b8dafa90>
Tabular val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x7fc6b83cd060>
Tabular test dataloader: <torch.utils.data.dataloader.DataLoader object at 0x7fc6b83cd120>

[INFO] Created SummaryWriter, saving to: runs/saint_runs/epochs_50_lr_1e-4_depth_4/2025-06-10--21:39:00
Epoch: 1 | train_loss: 0.2099 | train_acc: 0.9162 | val_loss: 0.2301 | val_acc: 0.9038 | test_loss: 0.2130 | test_acc: 0.9160
Epoch: 2 | train_loss: 0.1901 | train_acc: 0.9236 | val_loss: 0.2281 | val_acc: 0.9038 | test_loss: 0.2101 | test_acc: 0.9134
Epoch: 3 | train_loss: 0.1822 | train_acc: 0.9272 | val_loss: 0.2430 | val_acc: 0.8927 | test_loss: 0.2190 | test_acc: 0.9072
Epoch: 4 | train_loss: 0.1797 | train_acc: 0.9283 | val_loss: 0.2354 | val_acc: 0.9053 | test_loss: 0.2244 | test_acc: 0.9141
Epoch: 5 | train_loss: 0.1781 | train_acc: 0.9285 | val_loss: 0.2339 | val_acc: 0.9021 | test_loss: 0.2215 | test_acc: 0.9138
Epoch: 6 | train_loss: 0.1728 | train_acc: 0.9307 | val_loss: 0.2299 | val_acc: 0.9096 | test_loss: 0.2160 | test_acc: 0.9108
Epoch: 7 | train_loss: 0.1702 | train_acc: 0.9312 | val_loss: 0.2358 | val_acc: 0.9041 | test_loss: 0.2150 | test_acc: 0.9140
Epoch: 8 | train_loss: 0.1658 | train_acc: 0.9335 | val_loss: 0.2413 | val_acc: 0.9024 | test_loss: 0.2423 | test_acc: 0.9113
Epoch: 9 | train_loss: 0.1642 | train_acc: 0.9331 | val_loss: 0.2405 | val_acc: 0.8968 | test_loss: 0.2247 | test_acc: 0.9102
Epoch: 10 | train_loss: 0.1577 | train_acc: 0.9356 | val_loss: 0.2610 | val_acc: 0.8891 | test_loss: 0.2455 | test_acc: 0.9006
Epoch: 11 | train_loss: 0.1555 | train_acc: 0.9359 | val_loss: 0.2681 | val_acc: 0.8970 | test_loss: 0.2607 | test_acc: 0.9002
Epoch: 12 | train_loss: 0.1506 | train_acc: 0.9400 | val_loss: 0.2550 | val_acc: 0.9030 | test_loss: 0.2397 | test_acc: 0.9115
Epoch: 13 | train_loss: 0.1462 | train_acc: 0.9411 | val_loss: 0.3081 | val_acc: 0.8968 | test_loss: 0.2968 | test_acc: 0.9023
Epoch: 14 | train_loss: 0.1442 | train_acc: 0.9414 | val_loss: 0.2840 | val_acc: 0.8983 | test_loss: 0.2608 | test_acc: 0.9046
Epoch: 15 | train_loss: 0.1378 | train_acc: 0.9443 | val_loss: 0.2785 | val_acc: 0.9010 | test_loss: 0.2720 | test_acc: 0.9085
Epoch: 16 | train_loss: 0.1355 | train_acc: 0.9447 | val_loss: 0.2977 | val_acc: 0.9036 | test_loss: 0.2695 | test_acc: 0.9091
Epoch: 17 | train_loss: 0.1311 | train_acc: 0.9462 | val_loss: 0.2813 | val_acc: 0.9017 | test_loss: 0.2800 | test_acc: 0.9081
Epoch: 18 | train_loss: 0.1268 | train_acc: 0.9486 | val_loss: 0.3241 | val_acc: 0.8989 | test_loss: 0.3218 | test_acc: 0.9013
Epoch: 19 | train_loss: 0.1238 | train_acc: 0.9487 | val_loss: 0.3166 | val_acc: 0.9025 | test_loss: 0.2977 | test_acc: 0.9021
