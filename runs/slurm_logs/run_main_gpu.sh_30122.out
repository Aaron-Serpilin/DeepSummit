torch version: 2.0.1
torchvision version: 0.15.2
mlxtend version: 0.23.4
Device is: cpu

[INFO] Data splits already exist under data/era5_data. Skipping split.
Weather train dataloader: <torch.utils.data.dataloader.DataLoader object at 0x7f24ad0e0100>
Weather val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x7f24ad0e0130>
Weather test dataloader: <torch.utils.data.dataloader.DataLoader object at 0x7f24ad0e01f0>

Passed Initialization (hidden_size % num_heads == 0)
[INFO] Created SummaryWriter, saving to: runs/stormer_runs/epochs_50_lr_1e-5_hidden_size_612_depth_12_heads_12/2025-06-17--16:16:50
Epoch: 1 | train_loss: 0.6670 | train_acc: 0.6728 | val_loss: 0.5585 | val_acc: 0.7160 | test_loss: 0.5564 | test_acc: 0.7183
Epoch: 2 | train_loss: 0.6125 | train_acc: 0.7173 | val_loss: 0.5374 | val_acc: 0.7332 | test_loss: 0.5360 | test_acc: 0.7277
Epoch: 3 | train_loss: 0.5910 | train_acc: 0.7343 | val_loss: 0.5317 | val_acc: 0.7371 | test_loss: 0.5218 | test_acc: 0.7355
Epoch: 4 | train_loss: 0.5796 | train_acc: 0.7396 | val_loss: 0.5130 | val_acc: 0.7560 | test_loss: 0.5057 | test_acc: 0.7532
Epoch: 5 | train_loss: 0.5678 | train_acc: 0.7468 | val_loss: 0.5072 | val_acc: 0.7567 | test_loss: 0.4988 | test_acc: 0.7571
Epoch: 6 | train_loss: 0.5580 | train_acc: 0.7529 | val_loss: 0.5166 | val_acc: 0.7495 | test_loss: 0.5028 | test_acc: 0.7500
Epoch: 7 | train_loss: 0.5516 | train_acc: 0.7533 | val_loss: 0.4965 | val_acc: 0.7654 | test_loss: 0.4903 | test_acc: 0.7606
Epoch: 8 | train_loss: 0.5445 | train_acc: 0.7588 | val_loss: 0.4960 | val_acc: 0.7583 | test_loss: 0.4877 | test_acc: 0.7532
Epoch: 9 | train_loss: 0.5393 | train_acc: 0.7626 | val_loss: 0.4882 | val_acc: 0.7617 | test_loss: 0.4823 | test_acc: 0.7553
Epoch: 10 | train_loss: 0.5343 | train_acc: 0.7616 | val_loss: 0.4885 | val_acc: 0.7613 | test_loss: 0.4808 | test_acc: 0.7615
Epoch: 11 | train_loss: 0.5291 | train_acc: 0.7639 | val_loss: 0.4929 | val_acc: 0.7587 | test_loss: 0.4826 | test_acc: 0.7576
Epoch: 12 | train_loss: 0.5254 | train_acc: 0.7660 | val_loss: 0.4807 | val_acc: 0.7668 | test_loss: 0.4727 | test_acc: 0.7638
Epoch: 13 | train_loss: 0.5222 | train_acc: 0.7691 | val_loss: 0.4764 | val_acc: 0.7672 | test_loss: 0.4685 | test_acc: 0.7633
Epoch: 14 | train_loss: 0.5186 | train_acc: 0.7693 | val_loss: 0.4801 | val_acc: 0.7659 | test_loss: 0.4700 | test_acc: 0.7656
Epoch: 15 | train_loss: 0.5156 | train_acc: 0.7723 | val_loss: 0.4854 | val_acc: 0.7647 | test_loss: 0.4762 | test_acc: 0.7608
Epoch: 16 | train_loss: 0.5128 | train_acc: 0.7712 | val_loss: 0.4723 | val_acc: 0.7656 | test_loss: 0.4679 | test_acc: 0.7636
Epoch: 17 | train_loss: 0.5116 | train_acc: 0.7748 | val_loss: 0.4718 | val_acc: 0.7675 | test_loss: 0.4620 | test_acc: 0.7619
Epoch: 18 | train_loss: 0.5095 | train_acc: 0.7725 | val_loss: 0.4680 | val_acc: 0.7716 | test_loss: 0.4612 | test_acc: 0.7668
Epoch: 19 | train_loss: 0.5065 | train_acc: 0.7744 | val_loss: 0.4732 | val_acc: 0.7682 | test_loss: 0.4663 | test_acc: 0.7606
Epoch: 20 | train_loss: 0.5062 | train_acc: 0.7740 | val_loss: 0.4732 | val_acc: 0.7693 | test_loss: 0.4639 | test_acc: 0.7663
Epoch: 21 | train_loss: 0.5012 | train_acc: 0.7771 | val_loss: 0.4721 | val_acc: 0.7691 | test_loss: 0.4648 | test_acc: 0.7675
Epoch: 22 | train_loss: 0.5013 | train_acc: 0.7758 | val_loss: 0.4715 | val_acc: 0.7705 | test_loss: 0.4648 | test_acc: 0.7663
Epoch: 23 | train_loss: 0.4994 | train_acc: 0.7771 | val_loss: 0.4706 | val_acc: 0.7698 | test_loss: 0.4613 | test_acc: 0.7693
Epoch: 24 | train_loss: 0.4999 | train_acc: 0.7767 | val_loss: 0.4701 | val_acc: 0.7746 | test_loss: 0.4619 | test_acc: 0.7675
Epoch: 25 | train_loss: 0.4969 | train_acc: 0.7766 | val_loss: 0.4689 | val_acc: 0.7663 | test_loss: 0.4618 | test_acc: 0.7640
Epoch: 26 | train_loss: 0.4971 | train_acc: 0.7771 | val_loss: 0.4629 | val_acc: 0.7748 | test_loss: 0.4552 | test_acc: 0.7698
Epoch: 27 | train_loss: 0.4938 | train_acc: 0.7779 | val_loss: 0.4656 | val_acc: 0.7732 | test_loss: 0.4585 | test_acc: 0.7705
Epoch: 28 | train_loss: 0.4917 | train_acc: 0.7808 | val_loss: 0.4669 | val_acc: 0.7744 | test_loss: 0.4570 | test_acc: 0.7672
Epoch: 29 | train_loss: 0.4911 | train_acc: 0.7806 | val_loss: 0.4658 | val_acc: 0.7711 | test_loss: 0.4578 | test_acc: 0.7723
Epoch: 30 | train_loss: 0.4924 | train_acc: 0.7787 | val_loss: 0.4682 | val_acc: 0.7730 | test_loss: 0.4580 | test_acc: 0.7721
Epoch: 31 | train_loss: 0.4887 | train_acc: 0.7823 | val_loss: 0.4643 | val_acc: 0.7790 | test_loss: 0.4604 | test_acc: 0.7711
Epoch: 32 | train_loss: 0.4885 | train_acc: 0.7815 | val_loss: 0.4693 | val_acc: 0.7767 | test_loss: 0.4559 | test_acc: 0.7741
Epoch: 33 | train_loss: 0.4890 | train_acc: 0.7806 | val_loss: 0.4620 | val_acc: 0.7711 | test_loss: 0.4559 | test_acc: 0.7711
Epoch: 34 | train_loss: 0.4865 | train_acc: 0.7815 | val_loss: 0.4708 | val_acc: 0.7730 | test_loss: 0.4572 | test_acc: 0.7762
Epoch: 35 | train_loss: 0.4853 | train_acc: 0.7835 | val_loss: 0.4664 | val_acc: 0.7755 | test_loss: 0.4580 | test_acc: 0.7757
Epoch: 36 | train_loss: 0.4842 | train_acc: 0.7848 | val_loss: 0.4624 | val_acc: 0.7780 | test_loss: 0.4585 | test_acc: 0.7732
Epoch: 37 | train_loss: 0.4850 | train_acc: 0.7837 | val_loss: 0.4659 | val_acc: 0.7760 | test_loss: 0.4593 | test_acc: 0.7716
Epoch: 38 | train_loss: 0.4844 | train_acc: 0.7804 | val_loss: 0.4621 | val_acc: 0.7744 | test_loss: 0.4536 | test_acc: 0.7778
Epoch: 39 | train_loss: 0.4844 | train_acc: 0.7819 | val_loss: 0.4659 | val_acc: 0.7707 | test_loss: 0.4570 | test_acc: 0.7727
Epoch: 40 | train_loss: 0.4832 | train_acc: 0.7833 | val_loss: 0.4604 | val_acc: 0.7792 | test_loss: 0.4531 | test_acc: 0.7753
Epoch: 41 | train_loss: 0.4816 | train_acc: 0.7850 | val_loss: 0.4615 | val_acc: 0.7739 | test_loss: 0.4580 | test_acc: 0.7737
Epoch: 42 | train_loss: 0.4814 | train_acc: 0.7831 | val_loss: 0.4640 | val_acc: 0.7787 | test_loss: 0.4610 | test_acc: 0.7734
Epoch: 43 | train_loss: 0.4803 | train_acc: 0.7851 | val_loss: 0.4647 | val_acc: 0.7734 | test_loss: 0.4568 | test_acc: 0.7727
Epoch: 44 | train_loss: 0.4789 | train_acc: 0.7832 | val_loss: 0.4635 | val_acc: 0.7773 | test_loss: 0.4550 | test_acc: 0.7716
Epoch: 45 | train_loss: 0.4806 | train_acc: 0.7840 | val_loss: 0.4607 | val_acc: 0.7762 | test_loss: 0.4512 | test_acc: 0.7762
Epoch: 46 | train_loss: 0.4777 | train_acc: 0.7852 | val_loss: 0.4583 | val_acc: 0.7790 | test_loss: 0.4506 | test_acc: 0.7783
Epoch: 47 | train_loss: 0.4774 | train_acc: 0.7842 | val_loss: 0.4633 | val_acc: 0.7780 | test_loss: 0.4577 | test_acc: 0.7776
Epoch: 48 | train_loss: 0.4778 | train_acc: 0.7850 | val_loss: 0.4600 | val_acc: 0.7771 | test_loss: 0.4532 | test_acc: 0.7792
Epoch: 49 | train_loss: 0.4759 | train_acc: 0.7861 | val_loss: 0.4653 | val_acc: 0.7757 | test_loss: 0.4553 | test_acc: 0.7773
Epoch: 50 | train_loss: 0.4756 | train_acc: 0.7858 | val_loss: 0.4637 | val_acc: 0.7783 | test_loss: 0.4539 | test_acc: 0.7755
[INFO] Saving model to: /var/scratch/ase347/DeepSummit/checkpoints/stormer_epochs_50_lr_1e-5_hidden_size_612_depth_12_heads_12.pth
