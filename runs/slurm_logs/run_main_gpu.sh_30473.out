torch version: 2.0.1
torchvision version: 0.15.2
mlxtend version: 0.23.4
Device is: cpu

[INFO] Data splits already exist under data/era5_data. Skipping split.
Weather train dataloader: <torch.utils.data.dataloader.DataLoader object at 0x7f5a445f4190>
Weather val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x7f5a445f4550>
Weather test dataloader: <torch.utils.data.dataloader.DataLoader object at 0x7f5a445f4760>

Passed Initialization (hidden_size % num_heads == 0)
[INFO] Created SummaryWriter, saving to: runs/stormer_runs/epochs_50_lr_1e-4_hidden_size_160_depth_12_heads_8_decay_1e-1/2025-06-19--02:58:25
Epoch: 1 | train_loss: 0.7640 | train_acc: 0.6796 | val_loss: 0.5555 | val_acc: 0.7261 | test_loss: 0.5515 | test_acc: 0.7222
Epoch: 2 | train_loss: 0.5909 | train_acc: 0.7275 | val_loss: 0.5261 | val_acc: 0.7408 | test_loss: 0.5221 | test_acc: 0.7381
Epoch: 3 | train_loss: 0.5694 | train_acc: 0.7397 | val_loss: 0.5142 | val_acc: 0.7426 | test_loss: 0.5042 | test_acc: 0.7413
Epoch: 4 | train_loss: 0.5502 | train_acc: 0.7487 | val_loss: 0.4991 | val_acc: 0.7502 | test_loss: 0.4964 | test_acc: 0.7516
Epoch: 5 | train_loss: 0.5397 | train_acc: 0.7538 | val_loss: 0.5010 | val_acc: 0.7631 | test_loss: 0.4999 | test_acc: 0.7523
Epoch: 6 | train_loss: 0.5337 | train_acc: 0.7555 | val_loss: 0.4907 | val_acc: 0.7574 | test_loss: 0.4842 | test_acc: 0.7541
Epoch: 7 | train_loss: 0.5238 | train_acc: 0.7603 | val_loss: 0.4816 | val_acc: 0.7661 | test_loss: 0.4846 | test_acc: 0.7599
Epoch: 8 | train_loss: 0.5186 | train_acc: 0.7626 | val_loss: 0.4992 | val_acc: 0.7548 | test_loss: 0.4907 | test_acc: 0.7445
Epoch: 9 | train_loss: 0.5124 | train_acc: 0.7618 | val_loss: 0.4905 | val_acc: 0.7615 | test_loss: 0.4850 | test_acc: 0.7594
Epoch: 10 | train_loss: 0.5097 | train_acc: 0.7623 | val_loss: 0.4920 | val_acc: 0.7567 | test_loss: 0.4944 | test_acc: 0.7525
Epoch: 11 | train_loss: 0.5052 | train_acc: 0.7648 | val_loss: 0.4877 | val_acc: 0.7599 | test_loss: 0.4867 | test_acc: 0.7507
Epoch: 12 | train_loss: 0.5015 | train_acc: 0.7650 | val_loss: 0.4775 | val_acc: 0.7659 | test_loss: 0.4763 | test_acc: 0.7665
Epoch: 13 | train_loss: 0.4998 | train_acc: 0.7671 | val_loss: 0.4753 | val_acc: 0.7686 | test_loss: 0.4691 | test_acc: 0.7619
Epoch: 14 | train_loss: 0.4972 | train_acc: 0.7638 | val_loss: 0.4837 | val_acc: 0.7626 | test_loss: 0.4760 | test_acc: 0.7606
Epoch: 15 | train_loss: 0.4930 | train_acc: 0.7683 | val_loss: 0.4767 | val_acc: 0.7714 | test_loss: 0.4720 | test_acc: 0.7617
Epoch: 16 | train_loss: 0.4904 | train_acc: 0.7699 | val_loss: 0.4803 | val_acc: 0.7682 | test_loss: 0.4714 | test_acc: 0.7613
Epoch: 17 | train_loss: 0.4881 | train_acc: 0.7703 | val_loss: 0.4711 | val_acc: 0.7744 | test_loss: 0.4683 | test_acc: 0.7665
Epoch: 18 | train_loss: 0.4861 | train_acc: 0.7701 | val_loss: 0.4809 | val_acc: 0.7578 | test_loss: 0.4744 | test_acc: 0.7606
Epoch: 19 | train_loss: 0.4822 | train_acc: 0.7722 | val_loss: 0.4775 | val_acc: 0.7677 | test_loss: 0.4669 | test_acc: 0.7638
Epoch: 20 | train_loss: 0.4831 | train_acc: 0.7707 | val_loss: 0.4788 | val_acc: 0.7705 | test_loss: 0.4682 | test_acc: 0.7668
Epoch: 21 | train_loss: 0.4807 | train_acc: 0.7715 | val_loss: 0.4732 | val_acc: 0.7670 | test_loss: 0.4698 | test_acc: 0.7659
Epoch: 22 | train_loss: 0.4788 | train_acc: 0.7725 | val_loss: 0.4686 | val_acc: 0.7675 | test_loss: 0.4624 | test_acc: 0.7695
Epoch: 23 | train_loss: 0.4785 | train_acc: 0.7705 | val_loss: 0.4775 | val_acc: 0.7709 | test_loss: 0.4671 | test_acc: 0.7649
Epoch: 24 | train_loss: 0.4756 | train_acc: 0.7721 | val_loss: 0.4653 | val_acc: 0.7746 | test_loss: 0.4649 | test_acc: 0.7700
Epoch: 25 | train_loss: 0.4718 | train_acc: 0.7748 | val_loss: 0.4723 | val_acc: 0.7686 | test_loss: 0.4662 | test_acc: 0.7615
Epoch: 26 | train_loss: 0.4728 | train_acc: 0.7744 | val_loss: 0.4793 | val_acc: 0.7615 | test_loss: 0.4703 | test_acc: 0.7590
Epoch: 27 | train_loss: 0.4695 | train_acc: 0.7757 | val_loss: 0.4742 | val_acc: 0.7714 | test_loss: 0.4697 | test_acc: 0.7672
Epoch: 28 | train_loss: 0.4682 | train_acc: 0.7764 | val_loss: 0.4679 | val_acc: 0.7702 | test_loss: 0.4639 | test_acc: 0.7654
Epoch: 29 | train_loss: 0.4701 | train_acc: 0.7738 | val_loss: 0.4687 | val_acc: 0.7711 | test_loss: 0.4700 | test_acc: 0.7675
Epoch: 30 | train_loss: 0.4680 | train_acc: 0.7741 | val_loss: 0.4684 | val_acc: 0.7730 | test_loss: 0.4646 | test_acc: 0.7700
Epoch: 31 | train_loss: 0.4661 | train_acc: 0.7759 | val_loss: 0.4674 | val_acc: 0.7698 | test_loss: 0.4646 | test_acc: 0.7707
Epoch: 32 | train_loss: 0.4636 | train_acc: 0.7780 | val_loss: 0.4696 | val_acc: 0.7767 | test_loss: 0.4682 | test_acc: 0.7675
Epoch: 33 | train_loss: 0.4639 | train_acc: 0.7749 | val_loss: 0.4654 | val_acc: 0.7790 | test_loss: 0.4625 | test_acc: 0.7718
Epoch: 34 | train_loss: 0.4645 | train_acc: 0.7757 | val_loss: 0.4672 | val_acc: 0.7707 | test_loss: 0.4640 | test_acc: 0.7665
Epoch: 35 | train_loss: 0.4607 | train_acc: 0.7771 | val_loss: 0.4635 | val_acc: 0.7737 | test_loss: 0.4648 | test_acc: 0.7727
Epoch: 36 | train_loss: 0.4610 | train_acc: 0.7782 | val_loss: 0.4673 | val_acc: 0.7767 | test_loss: 0.4617 | test_acc: 0.7714
Epoch: 37 | train_loss: 0.4613 | train_acc: 0.7755 | val_loss: 0.4642 | val_acc: 0.7732 | test_loss: 0.4642 | test_acc: 0.7707
Epoch: 38 | train_loss: 0.4621 | train_acc: 0.7752 | val_loss: 0.4722 | val_acc: 0.7718 | test_loss: 0.4617 | test_acc: 0.7705
Epoch: 39 | train_loss: 0.4588 | train_acc: 0.7765 | val_loss: 0.4643 | val_acc: 0.7757 | test_loss: 0.4610 | test_acc: 0.7702
Epoch: 40 | train_loss: 0.4591 | train_acc: 0.7774 | val_loss: 0.4681 | val_acc: 0.7769 | test_loss: 0.4634 | test_acc: 0.7705
Epoch: 41 | train_loss: 0.4557 | train_acc: 0.7779 | val_loss: 0.4636 | val_acc: 0.7750 | test_loss: 0.4614 | test_acc: 0.7656
Epoch: 42 | train_loss: 0.4536 | train_acc: 0.7801 | val_loss: 0.4634 | val_acc: 0.7783 | test_loss: 0.4574 | test_acc: 0.7727
Epoch: 43 | train_loss: 0.4562 | train_acc: 0.7786 | val_loss: 0.4619 | val_acc: 0.7778 | test_loss: 0.4616 | test_acc: 0.7711
Epoch: 44 | train_loss: 0.4549 | train_acc: 0.7797 | val_loss: 0.4663 | val_acc: 0.7727 | test_loss: 0.4603 | test_acc: 0.7721
Epoch: 45 | train_loss: 0.4543 | train_acc: 0.7783 | val_loss: 0.4617 | val_acc: 0.7732 | test_loss: 0.4578 | test_acc: 0.7725
Epoch: 46 | train_loss: 0.4534 | train_acc: 0.7799 | val_loss: 0.4621 | val_acc: 0.7780 | test_loss: 0.4557 | test_acc: 0.7727
Epoch: 47 | train_loss: 0.4519 | train_acc: 0.7789 | val_loss: 0.4615 | val_acc: 0.7734 | test_loss: 0.4633 | test_acc: 0.7691
Epoch: 48 | train_loss: 0.4513 | train_acc: 0.7796 | val_loss: 0.4615 | val_acc: 0.7762 | test_loss: 0.4549 | test_acc: 0.7787
Epoch: 49 | train_loss: 0.4525 | train_acc: 0.7788 | val_loss: 0.4679 | val_acc: 0.7709 | test_loss: 0.4646 | test_acc: 0.7709
Epoch: 50 | train_loss: 0.4531 | train_acc: 0.7796 | val_loss: 0.4559 | val_acc: 0.7771 | test_loss: 0.4583 | test_acc: 0.7721
[INFO] Saving model to: /var/scratch/ase347/DeepSummit/checkpoints/stormer_epochs_50_lr_1e-4_hidden_size_160_depth_12_heads_8_decay_1e-1.pth
