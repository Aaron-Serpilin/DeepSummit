
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/var/scratch/ase347/DeepSummit/src/scripts/train_saint.py", line 9, in <module>
    import torchvision
  File "/var/scratch/ase347/anaconda3/envs/deepsummit/lib/python3.10/site-packages/torchvision/__init__.py", line 6, in <module>
    from torchvision import datasets, io, models, ops, transforms, utils
  File "/var/scratch/ase347/anaconda3/envs/deepsummit/lib/python3.10/site-packages/torchvision/models/__init__.py", line 17, in <module>
    from . import detection, optical_flow, quantization, segmentation, video
  File "/var/scratch/ase347/anaconda3/envs/deepsummit/lib/python3.10/site-packages/torchvision/models/detection/__init__.py", line 1, in <module>
    from .faster_rcnn import *
  File "/var/scratch/ase347/anaconda3/envs/deepsummit/lib/python3.10/site-packages/torchvision/models/detection/faster_rcnn.py", line 16, in <module>
    from .anchor_utils import AnchorGenerator
  File "/var/scratch/ase347/anaconda3/envs/deepsummit/lib/python3.10/site-packages/torchvision/models/detection/anchor_utils.py", line 10, in <module>
    class AnchorGenerator(nn.Module):
  File "/var/scratch/ase347/anaconda3/envs/deepsummit/lib/python3.10/site-packages/torchvision/models/detection/anchor_utils.py", line 63, in AnchorGenerator
    device: torch.device = torch.device("cpu"),
/var/scratch/ase347/anaconda3/envs/deepsummit/lib/python3.10/site-packages/torchvision/models/detection/anchor_utils.py:63: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /opt/conda/conda-bld/pytorch_1682343904639/work/torch/csrc/utils/tensor_numpy.cpp:84.)
  device: torch.device = torch.device("cpu"),
torch version: 2.0.1
torchvision version: 0.15.2
mlxtend version: 0.23.4
numpy version: 2.0.1
Device is: cpu

[INFO] Data splits already exist under data/himalayas_data. Skipping split.
Tabular train dataloader: <torch.utils.data.dataloader.DataLoader object at 0x7fc5da58fac0>
Tabular val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x7fc5d9c41090>
Tabular test dataloader: <torch.utils.data.dataloader.DataLoader object at 0x7fc5d9c41150>

[INFO] Created SummaryWriter, saving to: runs/saint_runs/epochs_50_lr_1e-3_depth_6/2025-06-10--14:05:59
  0%|          | 0/50 [00:00<?, ?it/s]  2%|▏         | 1/50 [03:20<2:43:23, 200.07s/it]Epoch: 1 | train_loss: 0.6906 | train_acc: 0.5489 | val_loss: 0.6880 | val_acc: 0.5558 | test_loss: 0.6868 | test_acc: 0.5656
  4%|▍         | 2/50 [06:17<2:29:36, 187.00s/it]Epoch: 2 | train_loss: 0.6882 | train_acc: 0.5536 | val_loss: 0.6869 | val_acc: 0.5558 | test_loss: 0.6849 | test_acc: 0.5656
  6%|▌         | 3/50 [09:23<2:25:56, 186.30s/it]Epoch: 3 | train_loss: 0.7106 | train_acc: 0.5480 | val_loss: 0.6871 | val_acc: 0.5558 | test_loss: 0.6852 | test_acc: 0.5656
  8%|▊         | 4/50 [12:06<2:15:54, 177.27s/it]Epoch: 4 | train_loss: 0.6872 | train_acc: 0.5546 | val_loss: 0.6870 | val_acc: 0.5558 | test_loss: 0.6852 | test_acc: 0.5656
 10%|█         | 5/50 [14:45<2:07:56, 170.59s/it]Epoch: 5 | train_loss: 0.6873 | train_acc: 0.5546 | val_loss: 0.6869 | val_acc: 0.5558 | test_loss: 0.6848 | test_acc: 0.5656
 12%|█▏        | 6/50 [17:29<2:03:26, 168.32s/it]Epoch: 6 | train_loss: 0.6872 | train_acc: 0.5546 | val_loss: 0.6870 | val_acc: 0.5558 | test_loss: 0.6851 | test_acc: 0.5656
 14%|█▍        | 7/50 [20:07<1:58:15, 165.01s/it]Epoch: 7 | train_loss: 0.6872 | train_acc: 0.5546 | val_loss: 0.6869 | val_acc: 0.5558 | test_loss: 0.6848 | test_acc: 0.5656
 16%|█▌        | 8/50 [22:48<1:54:28, 163.52s/it]Epoch: 8 | train_loss: 0.6872 | train_acc: 0.5546 | val_loss: 0.6869 | val_acc: 0.5558 | test_loss: 0.6846 | test_acc: 0.5656
 18%|█▊        | 9/50 [25:30<1:51:37, 163.35s/it]Epoch: 9 | train_loss: 0.6872 | train_acc: 0.5546 | val_loss: 0.6870 | val_acc: 0.5558 | test_loss: 0.6846 | test_acc: 0.5656
 20%|██        | 10/50 [28:18<1:49:45, 164.64s/it]Epoch: 10 | train_loss: 0.7735 | train_acc: 0.5469 | val_loss: 0.6875 | val_acc: 0.5558 | test_loss: 0.6846 | test_acc: 0.5656
 22%|██▏       | 11/50 [31:07<1:47:49, 165.87s/it]Epoch: 11 | train_loss: 0.6875 | train_acc: 0.5543 | val_loss: 0.6871 | val_acc: 0.5558 | test_loss: 0.6853 | test_acc: 0.5656
 24%|██▍       | 12/50 [33:55<1:45:30, 166.58s/it]Epoch: 12 | train_loss: 0.6872 | train_acc: 0.5547 | val_loss: 0.6869 | val_acc: 0.5558 | test_loss: 0.6846 | test_acc: 0.5656
 26%|██▌       | 13/50 [36:49<1:44:08, 168.87s/it]Epoch: 13 | train_loss: 0.6873 | train_acc: 0.5546 | val_loss: 0.6869 | val_acc: 0.5558 | test_loss: 0.6848 | test_acc: 0.5656
 28%|██▊       | 14/50 [39:36<1:40:55, 168.20s/it]Epoch: 14 | train_loss: 0.6873 | train_acc: 0.5546 | val_loss: 0.6869 | val_acc: 0.5558 | test_loss: 0.6847 | test_acc: 0.5656
 30%|███       | 15/50 [42:41<1:41:09, 173.42s/it]Epoch: 15 | train_loss: 0.6872 | train_acc: 0.5546 | val_loss: 0.6869 | val_acc: 0.5558 | test_loss: 0.6849 | test_acc: 0.5656
 32%|███▏      | 16/50 [45:41<1:39:22, 175.35s/it]Epoch: 16 | train_loss: 0.6872 | train_acc: 0.5546 | val_loss: 0.6870 | val_acc: 0.5558 | test_loss: 0.6851 | test_acc: 0.5656
 34%|███▍      | 17/50 [48:28<1:35:00, 172.75s/it]Epoch: 17 | train_loss: 0.6872 | train_acc: 0.5547 | val_loss: 0.6869 | val_acc: 0.5558 | test_loss: 0.6849 | test_acc: 0.5656
 36%|███▌      | 18/50 [51:15<1:31:13, 171.04s/it]Epoch: 18 | train_loss: 0.8239 | train_acc: 0.5534 | val_loss: 0.6870 | val_acc: 0.5558 | test_loss: 0.6845 | test_acc: 0.5656
 38%|███▊      | 19/50 [54:17<1:30:08, 174.47s/it]Epoch: 19 | train_loss: 0.6872 | train_acc: 0.5546 | val_loss: 0.6869 | val_acc: 0.5558 | test_loss: 0.6846 | test_acc: 0.5656
 40%|████      | 20/50 [57:20<1:28:25, 176.86s/it]Epoch: 20 | train_loss: 0.6872 | train_acc: 0.5546 | val_loss: 0.6869 | val_acc: 0.5558 | test_loss: 0.6846 | test_acc: 0.5656
 42%|████▏     | 21/50 [1:00:25<1:26:42, 179.40s/it]Epoch: 21 | train_loss: 0.6872 | train_acc: 0.5546 | val_loss: 0.6869 | val_acc: 0.5558 | test_loss: 0.6847 | test_acc: 0.5656
 44%|████▍     | 22/50 [1:03:40<1:25:52, 184.02s/it]Epoch: 22 | train_loss: 0.6872 | train_acc: 0.5547 | val_loss: 0.6869 | val_acc: 0.5558 | test_loss: 0.6847 | test_acc: 0.5656
 46%|████▌     | 23/50 [1:06:52<1:23:54, 186.47s/it]Epoch: 23 | train_loss: 0.6872 | train_acc: 0.5547 | val_loss: 0.6869 | val_acc: 0.5558 | test_loss: 0.6847 | test_acc: 0.5656
 48%|████▊     | 24/50 [1:10:27<1:24:27, 194.89s/it]Epoch: 24 | train_loss: 0.6872 | train_acc: 0.5546 | val_loss: 0.6869 | val_acc: 0.5558 | test_loss: 0.6846 | test_acc: 0.5656
 50%|█████     | 25/50 [1:13:50<1:22:13, 197.35s/it]Epoch: 25 | train_loss: 0.6872 | train_acc: 0.5547 | val_loss: 0.6869 | val_acc: 0.5558 | test_loss: 0.6849 | test_acc: 0.5656
 52%|█████▏    | 26/50 [1:17:12<1:19:33, 198.88s/it]Epoch: 26 | train_loss: 0.6872 | train_acc: 0.5546 | val_loss: 0.6869 | val_acc: 0.5558 | test_loss: 0.6846 | test_acc: 0.5656
 54%|█████▍    | 27/50 [1:20:28<1:15:51, 197.90s/it]Epoch: 27 | train_loss: 0.6872 | train_acc: 0.5546 | val_loss: 0.6869 | val_acc: 0.5558 | test_loss: 0.6847 | test_acc: 0.5656
 56%|█████▌    | 28/50 [1:23:51<1:13:09, 199.54s/it]Epoch: 28 | train_loss: 0.6872 | train_acc: 0.5546 | val_loss: 0.6869 | val_acc: 0.5558 | test_loss: 0.6849 | test_acc: 0.5656
 58%|█████▊    | 29/50 [1:27:15<1:10:20, 200.98s/it]Epoch: 29 | train_loss: 0.6872 | train_acc: 0.5547 | val_loss: 0.6870 | val_acc: 0.5558 | test_loss: 0.6849 | test_acc: 0.5656
 60%|██████    | 30/50 [1:30:42<1:07:34, 202.73s/it]Epoch: 30 | train_loss: 0.6872 | train_acc: 0.5546 | val_loss: 0.6870 | val_acc: 0.5558 | test_loss: 0.6849 | test_acc: 0.5656
 62%|██████▏   | 31/50 [1:34:05<1:04:09, 202.62s/it]Epoch: 31 | train_loss: 0.6872 | train_acc: 0.5546 | val_loss: 0.6869 | val_acc: 0.5558 | test_loss: 0.6848 | test_acc: 0.5656
 64%|██████▍   | 32/50 [1:37:36<1:01:36, 205.35s/it]Epoch: 32 | train_loss: 0.6872 | train_acc: 0.5547 | val_loss: 0.6869 | val_acc: 0.5558 | test_loss: 0.6848 | test_acc: 0.5656
 66%|██████▌   | 33/50 [1:40:57<57:49, 204.07s/it]  Epoch: 33 | train_loss: 0.6872 | train_acc: 0.5546 | val_loss: 0.6870 | val_acc: 0.5558 | test_loss: 0.6851 | test_acc: 0.5656
 68%|██████▊   | 34/50 [1:44:23<54:33, 204.58s/it]Epoch: 34 | train_loss: 0.6872 | train_acc: 0.5546 | val_loss: 0.6869 | val_acc: 0.5558 | test_loss: 0.6847 | test_acc: 0.5656
 70%|███████   | 35/50 [1:47:46<50:59, 203.97s/it]Epoch: 35 | train_loss: 0.6872 | train_acc: 0.5546 | val_loss: 0.6869 | val_acc: 0.5558 | test_loss: 0.6848 | test_acc: 0.5656
 72%|███████▏  | 36/50 [1:51:16<48:02, 205.86s/it]Epoch: 36 | train_loss: 0.6872 | train_acc: 0.5546 | val_loss: 0.6869 | val_acc: 0.5558 | test_loss: 0.6848 | test_acc: 0.5656
 74%|███████▍  | 37/50 [1:54:39<44:23, 204.90s/it]Epoch: 37 | train_loss: 0.6872 | train_acc: 0.5546 | val_loss: 0.6869 | val_acc: 0.5558 | test_loss: 0.6847 | test_acc: 0.5656
 76%|███████▌  | 38/50 [1:58:10<41:23, 206.97s/it]Epoch: 38 | train_loss: 0.6872 | train_acc: 0.5547 | val_loss: 0.6870 | val_acc: 0.5558 | test_loss: 0.6850 | test_acc: 0.5656
 78%|███████▊  | 39/50 [2:01:33<37:42, 205.72s/it]Epoch: 39 | train_loss: 0.6872 | train_acc: 0.5546 | val_loss: 0.6870 | val_acc: 0.5558 | test_loss: 0.6849 | test_acc: 0.5656
 80%|████████  | 40/50 [2:04:56<34:08, 204.81s/it]Epoch: 40 | train_loss: 0.6872 | train_acc: 0.5546 | val_loss: 0.6870 | val_acc: 0.5558 | test_loss: 0.6845 | test_acc: 0.5656
 82%|████████▏ | 41/50 [2:08:24<30:52, 205.88s/it]Epoch: 41 | train_loss: 0.6872 | train_acc: 0.5547 | val_loss: 0.6870 | val_acc: 0.5558 | test_loss: 0.6851 | test_acc: 0.5656
 84%|████████▍ | 42/50 [2:11:57<27:43, 207.89s/it]Epoch: 42 | train_loss: 0.6872 | train_acc: 0.5546 | val_loss: 0.6869 | val_acc: 0.5558 | test_loss: 0.6848 | test_acc: 0.5656
 86%|████████▌ | 43/50 [2:15:23<24:10, 207.28s/it]Epoch: 43 | train_loss: 0.6872 | train_acc: 0.5547 | val_loss: 0.6871 | val_acc: 0.5558 | test_loss: 0.6845 | test_acc: 0.5656
 88%|████████▊ | 44/50 [2:18:56<20:54, 209.09s/it]Epoch: 44 | train_loss: 0.6873 | train_acc: 0.5546 | val_loss: 0.6869 | val_acc: 0.5558 | test_loss: 0.6847 | test_acc: 0.5656
 90%|█████████ | 45/50 [2:21:58<16:44, 200.93s/it]Epoch: 45 | train_loss: 0.7299 | train_acc: 0.5532 | val_loss: 0.6869 | val_acc: 0.5558 | test_loss: 0.6848 | test_acc: 0.5656
 92%|█████████▏| 46/50 [2:25:11<13:14, 198.55s/it]Epoch: 46 | train_loss: 0.6872 | train_acc: 0.5547 | val_loss: 0.6870 | val_acc: 0.5558 | test_loss: 0.6850 | test_acc: 0.5656
 94%|█████████▍| 47/50 [2:28:02<09:31, 190.41s/it]Epoch: 47 | train_loss: 0.6872 | train_acc: 0.5546 | val_loss: 0.6870 | val_acc: 0.5558 | test_loss: 0.6850 | test_acc: 0.5656
 96%|█████████▌| 48/50 [2:31:08<06:17, 188.85s/it]Epoch: 48 | train_loss: 0.6872 | train_acc: 0.5546 | val_loss: 0.6870 | val_acc: 0.5558 | test_loss: 0.6849 | test_acc: 0.5656
 98%|█████████▊| 49/50 [2:34:05<03:05, 185.38s/it]Epoch: 49 | train_loss: 0.6872 | train_acc: 0.5547 | val_loss: 0.6869 | val_acc: 0.5558 | test_loss: 0.6848 | test_acc: 0.5656
100%|██████████| 50/50 [2:37:17<00:00, 187.48s/it]100%|██████████| 50/50 [2:37:17<00:00, 188.75s/it]
Epoch: 50 | train_loss: 0.6872 | train_acc: 0.5546 | val_loss: 0.6870 | val_acc: 0.5558 | test_loss: 0.6846 | test_acc: 0.5656
[INFO] Saving model to: /var/scratch/ase347/DeepSummit/checkpoints/saint_epochs_50_lr_1e-3_depth_6.pth
