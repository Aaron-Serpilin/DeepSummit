torch version: 2.0.1
torchvision version: 0.15.2
mlxtend version: 0.23.4
numpy version: 2.0.1
Device is: cpu

[INFO] Data splits already exist under data/himalayas_data. Skipping split.
Tabular train dataloader: <torch.utils.data.dataloader.DataLoader object at 0x7fcb618dfa30>
Tabular val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x7fcb60f91000>
Tabular test dataloader: <torch.utils.data.dataloader.DataLoader object at 0x7fcb60f910c0>

[INFO] Created SummaryWriter, saving to: runs/saint_runs/epochs_50_lr_1e-4_depth_4/2025-06-10--20:02:29
Epoch: 1 | train_loss: 0.2099 | train_acc: 0.9162 | val_loss: 0.2301 | val_acc: 0.9038 | test_loss: 0.2130 | test_acc: 0.9160
Epoch: 2 | train_loss: 0.1901 | train_acc: 0.9236 | val_loss: 0.2281 | val_acc: 0.9038 | test_loss: 0.2101 | test_acc: 0.9134
Epoch: 3 | train_loss: 0.1822 | train_acc: 0.9272 | val_loss: 0.2430 | val_acc: 0.8927 | test_loss: 0.2190 | test_acc: 0.9072
Epoch: 4 | train_loss: 0.1797 | train_acc: 0.9283 | val_loss: 0.2354 | val_acc: 0.9053 | test_loss: 0.2244 | test_acc: 0.9141
Epoch: 5 | train_loss: 0.1781 | train_acc: 0.9285 | val_loss: 0.2339 | val_acc: 0.9021 | test_loss: 0.2215 | test_acc: 0.9138
Epoch: 6 | train_loss: 0.1728 | train_acc: 0.9307 | val_loss: 0.2299 | val_acc: 0.9096 | test_loss: 0.2160 | test_acc: 0.9108
Epoch: 7 | train_loss: 0.1702 | train_acc: 0.9312 | val_loss: 0.2358 | val_acc: 0.9041 | test_loss: 0.2150 | test_acc: 0.9140
Epoch: 8 | train_loss: 0.1658 | train_acc: 0.9335 | val_loss: 0.2413 | val_acc: 0.9024 | test_loss: 0.2423 | test_acc: 0.9113
Epoch: 9 | train_loss: 0.1642 | train_acc: 0.9331 | val_loss: 0.2405 | val_acc: 0.8968 | test_loss: 0.2247 | test_acc: 0.9102
Epoch: 10 | train_loss: 0.1577 | train_acc: 0.9356 | val_loss: 0.2610 | val_acc: 0.8891 | test_loss: 0.2455 | test_acc: 0.9006
Epoch: 11 | train_loss: 0.1555 | train_acc: 0.9359 | val_loss: 0.2681 | val_acc: 0.8970 | test_loss: 0.2607 | test_acc: 0.9002
Epoch: 12 | train_loss: 0.1506 | train_acc: 0.9400 | val_loss: 0.2550 | val_acc: 0.9030 | test_loss: 0.2397 | test_acc: 0.9115
Epoch: 13 | train_loss: 0.1462 | train_acc: 0.9411 | val_loss: 0.3081 | val_acc: 0.8968 | test_loss: 0.2968 | test_acc: 0.9023
Epoch: 14 | train_loss: 0.1442 | train_acc: 0.9414 | val_loss: 0.2840 | val_acc: 0.8983 | test_loss: 0.2608 | test_acc: 0.9046
Epoch: 15 | train_loss: 0.1378 | train_acc: 0.9443 | val_loss: 0.2785 | val_acc: 0.9010 | test_loss: 0.2720 | test_acc: 0.9085
Epoch: 16 | train_loss: 0.1355 | train_acc: 0.9447 | val_loss: 0.2977 | val_acc: 0.9036 | test_loss: 0.2695 | test_acc: 0.9091
Epoch: 17 | train_loss: 0.1311 | train_acc: 0.9462 | val_loss: 0.2813 | val_acc: 0.9017 | test_loss: 0.2800 | test_acc: 0.9081
Epoch: 18 | train_loss: 0.1268 | train_acc: 0.9486 | val_loss: 0.3241 | val_acc: 0.8989 | test_loss: 0.3218 | test_acc: 0.9013
Epoch: 19 | train_loss: 0.1238 | train_acc: 0.9487 | val_loss: 0.3166 | val_acc: 0.9025 | test_loss: 0.2977 | test_acc: 0.9021
Epoch: 20 | train_loss: 0.1194 | train_acc: 0.9516 | val_loss: 0.3918 | val_acc: 0.8853 | test_loss: 0.3537 | test_acc: 0.8908
Epoch: 21 | train_loss: 0.1190 | train_acc: 0.9522 | val_loss: 0.3007 | val_acc: 0.8996 | test_loss: 0.2962 | test_acc: 0.8993
Epoch: 22 | train_loss: 0.1152 | train_acc: 0.9531 | val_loss: 0.3398 | val_acc: 0.8998 | test_loss: 0.3527 | test_acc: 0.8976
Epoch: 23 | train_loss: 0.1118 | train_acc: 0.9548 | val_loss: 0.3490 | val_acc: 0.8959 | test_loss: 0.3673 | test_acc: 0.8955
Epoch: 24 | train_loss: 0.1090 | train_acc: 0.9556 | val_loss: 0.3513 | val_acc: 0.9011 | test_loss: 0.3791 | test_acc: 0.8942
Epoch: 25 | train_loss: 0.1090 | train_acc: 0.9549 | val_loss: 0.3817 | val_acc: 0.8976 | test_loss: 0.4051 | test_acc: 0.8980
Epoch: 26 | train_loss: 0.1049 | train_acc: 0.9578 | val_loss: 0.3735 | val_acc: 0.8972 | test_loss: 0.3740 | test_acc: 0.8978
Epoch: 27 | train_loss: 0.1018 | train_acc: 0.9580 | val_loss: 0.3896 | val_acc: 0.8972 | test_loss: 0.3594 | test_acc: 0.8947
Epoch: 28 | train_loss: 0.1016 | train_acc: 0.9582 | val_loss: 0.4165 | val_acc: 0.8985 | test_loss: 0.4169 | test_acc: 0.8949
Epoch: 29 | train_loss: 0.0996 | train_acc: 0.9591 | val_loss: 0.4241 | val_acc: 0.8970 | test_loss: 0.4309 | test_acc: 0.8976
Epoch: 30 | train_loss: 0.0970 | train_acc: 0.9606 | val_loss: 0.3842 | val_acc: 0.8910 | test_loss: 0.3677 | test_acc: 0.8940
Epoch: 31 | train_loss: 0.0950 | train_acc: 0.9612 | val_loss: 0.4075 | val_acc: 0.8895 | test_loss: 0.4093 | test_acc: 0.8931
Epoch: 32 | train_loss: 0.0937 | train_acc: 0.9622 | val_loss: 0.3697 | val_acc: 0.8985 | test_loss: 0.3592 | test_acc: 0.8968
Epoch: 33 | train_loss: 0.0943 | train_acc: 0.9617 | val_loss: 0.4091 | val_acc: 0.8992 | test_loss: 0.3884 | test_acc: 0.8963
Epoch: 34 | train_loss: 0.0909 | train_acc: 0.9632 | val_loss: 0.4031 | val_acc: 0.8976 | test_loss: 0.3626 | test_acc: 0.8998
Epoch: 35 | train_loss: 0.0891 | train_acc: 0.9642 | val_loss: 0.4491 | val_acc: 0.8968 | test_loss: 0.4371 | test_acc: 0.8947
Epoch: 36 | train_loss: 0.0875 | train_acc: 0.9640 | val_loss: 0.4472 | val_acc: 0.8947 | test_loss: 0.4376 | test_acc: 0.8966
Epoch: 37 | train_loss: 0.0890 | train_acc: 0.9645 | val_loss: 0.4748 | val_acc: 0.8942 | test_loss: 0.4894 | test_acc: 0.8887
Epoch: 38 | train_loss: 0.0855 | train_acc: 0.9647 | val_loss: 0.5344 | val_acc: 0.8906 | test_loss: 0.5332 | test_acc: 0.8912
Epoch: 39 | train_loss: 0.0831 | train_acc: 0.9670 | val_loss: 0.4770 | val_acc: 0.8955 | test_loss: 0.4634 | test_acc: 0.8934
Epoch: 40 | train_loss: 0.0832 | train_acc: 0.9668 | val_loss: 0.4741 | val_acc: 0.8911 | test_loss: 0.4772 | test_acc: 0.8889
Epoch: 41 | train_loss: 0.0832 | train_acc: 0.9660 | val_loss: 0.4639 | val_acc: 0.8896 | test_loss: 0.4562 | test_acc: 0.8949
Epoch: 42 | train_loss: 0.0832 | train_acc: 0.9661 | val_loss: 0.4695 | val_acc: 0.8908 | test_loss: 0.4857 | test_acc: 0.8872
Epoch: 43 | train_loss: 0.0832 | train_acc: 0.9663 | val_loss: 0.4165 | val_acc: 0.8866 | test_loss: 0.4120 | test_acc: 0.8904
Epoch: 44 | train_loss: 0.0805 | train_acc: 0.9673 | val_loss: 0.6044 | val_acc: 0.8864 | test_loss: 0.5746 | test_acc: 0.8906
Epoch: 45 | train_loss: 0.0794 | train_acc: 0.9674 | val_loss: 0.4776 | val_acc: 0.8864 | test_loss: 0.4698 | test_acc: 0.8861
Epoch: 46 | train_loss: 0.0783 | train_acc: 0.9684 | val_loss: 0.4780 | val_acc: 0.8968 | test_loss: 0.4557 | test_acc: 0.8953
Epoch: 47 | train_loss: 0.0777 | train_acc: 0.9679 | val_loss: 0.5523 | val_acc: 0.8851 | test_loss: 0.5046 | test_acc: 0.8929
Epoch: 48 | train_loss: 0.0755 | train_acc: 0.9689 | val_loss: 0.4359 | val_acc: 0.8849 | test_loss: 0.4030 | test_acc: 0.8942
Epoch: 49 | train_loss: 0.0773 | train_acc: 0.9689 | val_loss: 0.5057 | val_acc: 0.8876 | test_loss: 0.4892 | test_acc: 0.8942
Epoch: 50 | train_loss: 0.0745 | train_acc: 0.9697 | val_loss: 0.5264 | val_acc: 0.8868 | test_loss: 0.5063 | test_acc: 0.8914
[INFO] Saving model to: /var/scratch/ase347/DeepSummit/checkpoints/saint_epochs_50_lr_1e-4_depth_4.pth
