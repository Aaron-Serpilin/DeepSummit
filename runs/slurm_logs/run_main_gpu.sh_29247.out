torch version: 2.0.1
torchvision version: 0.15.2
mlxtend version: 0.23.4
numpy version: 2.0.1
Device is: cpu

[INFO] Data splits already exist under data/himalayas_data. Skipping split.
Tabular train dataloader: <torch.utils.data.dataloader.DataLoader object at 0x7f5e93ac39d0>
Tabular val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x7f5e93174fa0>
Tabular test dataloader: <torch.utils.data.dataloader.DataLoader object at 0x7f5e93175060>

[INFO] Created SummaryWriter, saving to: runs/saint_runs/epochs_50_lr_1e-5_depth_3_dropout_5e-1_heads_4/2025-06-11--16:59:54
Epoch: 1 | train_loss: 0.2596 | train_acc: 0.8919 | val_loss: 0.2327 | val_acc: 0.9021 | test_loss: 0.2278 | test_acc: 0.9059
Epoch: 2 | train_loss: 0.1965 | train_acc: 0.9209 | val_loss: 0.2397 | val_acc: 0.9015 | test_loss: 0.2266 | test_acc: 0.9008
Epoch: 3 | train_loss: 0.1895 | train_acc: 0.9235 | val_loss: 0.2292 | val_acc: 0.9032 | test_loss: 0.2172 | test_acc: 0.9083
Epoch: 4 | train_loss: 0.1870 | train_acc: 0.9250 | val_loss: 0.2267 | val_acc: 0.9062 | test_loss: 0.2162 | test_acc: 0.9091
Epoch: 5 | train_loss: 0.1848 | train_acc: 0.9257 | val_loss: 0.2260 | val_acc: 0.9058 | test_loss: 0.2130 | test_acc: 0.9100
Epoch: 6 | train_loss: 0.1823 | train_acc: 0.9264 | val_loss: 0.2192 | val_acc: 0.9091 | test_loss: 0.2084 | test_acc: 0.9151
Epoch: 7 | train_loss: 0.1801 | train_acc: 0.9280 | val_loss: 0.2211 | val_acc: 0.9098 | test_loss: 0.2079 | test_acc: 0.9158
Epoch: 8 | train_loss: 0.1791 | train_acc: 0.9285 | val_loss: 0.2275 | val_acc: 0.9023 | test_loss: 0.2117 | test_acc: 0.9119
Epoch: 9 | train_loss: 0.1783 | train_acc: 0.9290 | val_loss: 0.2231 | val_acc: 0.9045 | test_loss: 0.2109 | test_acc: 0.9113
Epoch: 10 | train_loss: 0.1765 | train_acc: 0.9293 | val_loss: 0.2368 | val_acc: 0.8989 | test_loss: 0.2148 | test_acc: 0.9072
Epoch: 11 | train_loss: 0.1765 | train_acc: 0.9292 | val_loss: 0.2296 | val_acc: 0.9019 | test_loss: 0.2094 | test_acc: 0.9141
Epoch: 12 | train_loss: 0.1751 | train_acc: 0.9299 | val_loss: 0.2204 | val_acc: 0.9081 | test_loss: 0.2059 | test_acc: 0.9149
Epoch: 13 | train_loss: 0.1744 | train_acc: 0.9308 | val_loss: 0.2393 | val_acc: 0.8993 | test_loss: 0.2118 | test_acc: 0.9117
Epoch: 14 | train_loss: 0.1741 | train_acc: 0.9306 | val_loss: 0.2322 | val_acc: 0.9030 | test_loss: 0.2089 | test_acc: 0.9132
Epoch: 15 | train_loss: 0.1728 | train_acc: 0.9301 | val_loss: 0.2249 | val_acc: 0.9081 | test_loss: 0.2054 | test_acc: 0.9153
Epoch: 16 | train_loss: 0.1724 | train_acc: 0.9316 | val_loss: 0.2359 | val_acc: 0.9015 | test_loss: 0.2092 | test_acc: 0.9098
Epoch: 17 | train_loss: 0.1722 | train_acc: 0.9309 | val_loss: 0.2295 | val_acc: 0.9055 | test_loss: 0.2056 | test_acc: 0.9145
Epoch: 18 | train_loss: 0.1710 | train_acc: 0.9315 | val_loss: 0.2271 | val_acc: 0.9049 | test_loss: 0.2052 | test_acc: 0.9138
Epoch: 19 | train_loss: 0.1705 | train_acc: 0.9320 | val_loss: 0.2329 | val_acc: 0.9053 | test_loss: 0.2064 | test_acc: 0.9155
Epoch: 20 | train_loss: 0.1699 | train_acc: 0.9321 | val_loss: 0.2349 | val_acc: 0.9023 | test_loss: 0.2092 | test_acc: 0.9102
Epoch: 21 | train_loss: 0.1691 | train_acc: 0.9322 | val_loss: 0.2275 | val_acc: 0.9057 | test_loss: 0.2032 | test_acc: 0.9172
Epoch: 22 | train_loss: 0.1687 | train_acc: 0.9324 | val_loss: 0.2415 | val_acc: 0.9036 | test_loss: 0.2112 | test_acc: 0.9102
Epoch: 23 | train_loss: 0.1680 | train_acc: 0.9324 | val_loss: 0.2431 | val_acc: 0.9008 | test_loss: 0.2135 | test_acc: 0.9104
Epoch: 24 | train_loss: 0.1670 | train_acc: 0.9332 | val_loss: 0.2448 | val_acc: 0.8977 | test_loss: 0.2153 | test_acc: 0.9096
Epoch: 25 | train_loss: 0.1665 | train_acc: 0.9336 | val_loss: 0.2321 | val_acc: 0.9036 | test_loss: 0.2076 | test_acc: 0.9145
Epoch: 26 | train_loss: 0.1652 | train_acc: 0.9332 | val_loss: 0.2431 | val_acc: 0.9015 | test_loss: 0.2100 | test_acc: 0.9126
Epoch: 27 | train_loss: 0.1652 | train_acc: 0.9327 | val_loss: 0.2543 | val_acc: 0.9028 | test_loss: 0.2153 | test_acc: 0.9130
Epoch: 28 | train_loss: 0.1641 | train_acc: 0.9346 | val_loss: 0.2542 | val_acc: 0.9036 | test_loss: 0.2141 | test_acc: 0.9125
Epoch: 29 | train_loss: 0.1641 | train_acc: 0.9338 | val_loss: 0.2444 | val_acc: 0.9021 | test_loss: 0.2121 | test_acc: 0.9134
Epoch: 30 | train_loss: 0.1632 | train_acc: 0.9346 | val_loss: 0.2728 | val_acc: 0.8978 | test_loss: 0.2235 | test_acc: 0.9091
Epoch: 31 | train_loss: 0.1628 | train_acc: 0.9340 | val_loss: 0.2720 | val_acc: 0.9008 | test_loss: 0.2220 | test_acc: 0.9157
Epoch: 32 | train_loss: 0.1613 | train_acc: 0.9347 | val_loss: 0.2615 | val_acc: 0.9006 | test_loss: 0.2179 | test_acc: 0.9141
Epoch: 33 | train_loss: 0.1616 | train_acc: 0.9353 | val_loss: 0.2754 | val_acc: 0.8987 | test_loss: 0.2193 | test_acc: 0.9125
Epoch: 34 | train_loss: 0.1611 | train_acc: 0.9345 | val_loss: 0.2665 | val_acc: 0.9009 | test_loss: 0.2153 | test_acc: 0.9147
Epoch: 35 | train_loss: 0.1598 | train_acc: 0.9362 | val_loss: 0.2661 | val_acc: 0.9009 | test_loss: 0.2184 | test_acc: 0.9132
Epoch: 36 | train_loss: 0.1588 | train_acc: 0.9359 | val_loss: 0.2745 | val_acc: 0.9038 | test_loss: 0.2154 | test_acc: 0.9166
Epoch: 37 | train_loss: 0.1585 | train_acc: 0.9363 | val_loss: 0.2510 | val_acc: 0.9030 | test_loss: 0.2113 | test_acc: 0.9164
Epoch: 38 | train_loss: 0.1573 | train_acc: 0.9368 | val_loss: 0.2659 | val_acc: 0.9002 | test_loss: 0.2196 | test_acc: 0.9140
Epoch: 39 | train_loss: 0.1567 | train_acc: 0.9367 | val_loss: 0.2791 | val_acc: 0.8962 | test_loss: 0.2216 | test_acc: 0.9096
Epoch: 40 | train_loss: 0.1559 | train_acc: 0.9378 | val_loss: 0.2747 | val_acc: 0.8987 | test_loss: 0.2218 | test_acc: 0.9125
Epoch: 41 | train_loss: 0.1558 | train_acc: 0.9379 | val_loss: 0.2684 | val_acc: 0.9013 | test_loss: 0.2191 | test_acc: 0.9138
Epoch: 42 | train_loss: 0.1553 | train_acc: 0.9379 | val_loss: 0.2824 | val_acc: 0.9000 | test_loss: 0.2263 | test_acc: 0.9119
Epoch: 43 | train_loss: 0.1551 | train_acc: 0.9381 | val_loss: 0.2869 | val_acc: 0.9000 | test_loss: 0.2286 | test_acc: 0.9134
Epoch: 44 | train_loss: 0.1528 | train_acc: 0.9388 | val_loss: 0.3197 | val_acc: 0.8979 | test_loss: 0.2440 | test_acc: 0.9087
Epoch: 45 | train_loss: 0.1528 | train_acc: 0.9386 | val_loss: 0.2753 | val_acc: 0.8979 | test_loss: 0.2226 | test_acc: 0.9104
Epoch: 46 | train_loss: 0.1527 | train_acc: 0.9383 | val_loss: 0.2654 | val_acc: 0.9004 | test_loss: 0.2196 | test_acc: 0.9125
Epoch: 47 | train_loss: 0.1510 | train_acc: 0.9393 | val_loss: 0.3188 | val_acc: 0.8977 | test_loss: 0.2420 | test_acc: 0.9104
Epoch: 48 | train_loss: 0.1509 | train_acc: 0.9394 | val_loss: 0.2913 | val_acc: 0.8976 | test_loss: 0.2268 | test_acc: 0.9125
Epoch: 49 | train_loss: 0.1502 | train_acc: 0.9392 | val_loss: 0.2899 | val_acc: 0.8970 | test_loss: 0.2277 | test_acc: 0.9130
Epoch: 50 | train_loss: 0.1494 | train_acc: 0.9400 | val_loss: 0.3218 | val_acc: 0.8966 | test_loss: 0.2362 | test_acc: 0.9136
[INFO] Saving model to: /var/scratch/ase347/DeepSummit/checkpoints/saint_epochs_50_lr_1e-5_depth_3_dropout_5e-1_heads_4.pth
