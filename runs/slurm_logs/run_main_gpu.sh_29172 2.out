torch version: 2.0.1
torchvision version: 0.15.2
mlxtend version: 0.23.4
numpy version: 2.0.1
Device is: cpu

[INFO] Data splits already exist under data/himalayas_data. Skipping split.
Tabular train dataloader: <torch.utils.data.dataloader.DataLoader object at 0x7ffb651e3a60>
Tabular val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x7ffb64891030>
Tabular test dataloader: <torch.utils.data.dataloader.DataLoader object at 0x7ffb648910f0>

[INFO] Created SummaryWriter, saving to: runs/saint_runs/epochs_50_lr_1e-5_depth_3_dropout_25e-2/2025-06-10--23:39:51
Epoch: 1 | train_loss: 0.2426 | train_acc: 0.9033 | val_loss: 0.2692 | val_acc: 0.8908 | test_loss: 0.2245 | test_acc: 0.9085
Epoch: 2 | train_loss: 0.1941 | train_acc: 0.9223 | val_loss: 0.2617 | val_acc: 0.8932 | test_loss: 0.2138 | test_acc: 0.9134
Epoch: 3 | train_loss: 0.1881 | train_acc: 0.9252 | val_loss: 0.2758 | val_acc: 0.8923 | test_loss: 0.2218 | test_acc: 0.9094
Epoch: 4 | train_loss: 0.1842 | train_acc: 0.9258 | val_loss: 0.2343 | val_acc: 0.9083 | test_loss: 0.2172 | test_acc: 0.9145
Epoch: 5 | train_loss: 0.1814 | train_acc: 0.9277 | val_loss: 0.2290 | val_acc: 0.9068 | test_loss: 0.2075 | test_acc: 0.9192
Epoch: 6 | train_loss: 0.1786 | train_acc: 0.9284 | val_loss: 0.2682 | val_acc: 0.8959 | test_loss: 0.2249 | test_acc: 0.9126
Epoch: 7 | train_loss: 0.1773 | train_acc: 0.9287 | val_loss: 0.2402 | val_acc: 0.9026 | test_loss: 0.2135 | test_acc: 0.9168
Epoch: 8 | train_loss: 0.1765 | train_acc: 0.9296 | val_loss: 0.2446 | val_acc: 0.8983 | test_loss: 0.2158 | test_acc: 0.9130
Epoch: 9 | train_loss: 0.1745 | train_acc: 0.9295 | val_loss: 0.2401 | val_acc: 0.9051 | test_loss: 0.2149 | test_acc: 0.9143
Epoch: 10 | train_loss: 0.1738 | train_acc: 0.9303 | val_loss: 0.2304 | val_acc: 0.9075 | test_loss: 0.2112 | test_acc: 0.9155
Epoch: 11 | train_loss: 0.1726 | train_acc: 0.9307 | val_loss: 0.2606 | val_acc: 0.8970 | test_loss: 0.2279 | test_acc: 0.9130
Epoch: 12 | train_loss: 0.1719 | train_acc: 0.9311 | val_loss: 0.2308 | val_acc: 0.9083 | test_loss: 0.2140 | test_acc: 0.9162
Epoch: 13 | train_loss: 0.1706 | train_acc: 0.9319 | val_loss: 0.2531 | val_acc: 0.9024 | test_loss: 0.2270 | test_acc: 0.9134
Epoch: 14 | train_loss: 0.1697 | train_acc: 0.9324 | val_loss: 0.2323 | val_acc: 0.9079 | test_loss: 0.2156 | test_acc: 0.9119
Epoch: 15 | train_loss: 0.1688 | train_acc: 0.9322 | val_loss: 0.2786 | val_acc: 0.8940 | test_loss: 0.2363 | test_acc: 0.9089
Epoch: 16 | train_loss: 0.1678 | train_acc: 0.9328 | val_loss: 0.2602 | val_acc: 0.8983 | test_loss: 0.2298 | test_acc: 0.9111
Epoch: 17 | train_loss: 0.1668 | train_acc: 0.9323 | val_loss: 0.2436 | val_acc: 0.9036 | test_loss: 0.2206 | test_acc: 0.9113
Epoch: 18 | train_loss: 0.1652 | train_acc: 0.9336 | val_loss: 0.2421 | val_acc: 0.9043 | test_loss: 0.2188 | test_acc: 0.9128
Epoch: 19 | train_loss: 0.1643 | train_acc: 0.9337 | val_loss: 0.2536 | val_acc: 0.9036 | test_loss: 0.2254 | test_acc: 0.9123
Epoch: 20 | train_loss: 0.1627 | train_acc: 0.9341 | val_loss: 0.2531 | val_acc: 0.9040 | test_loss: 0.2260 | test_acc: 0.9117
Epoch: 21 | train_loss: 0.1616 | train_acc: 0.9346 | val_loss: 0.2650 | val_acc: 0.8972 | test_loss: 0.2367 | test_acc: 0.9051
Epoch: 22 | train_loss: 0.1612 | train_acc: 0.9355 | val_loss: 0.2464 | val_acc: 0.8992 | test_loss: 0.2238 | test_acc: 0.9121
Epoch: 23 | train_loss: 0.1598 | train_acc: 0.9354 | val_loss: 0.2646 | val_acc: 0.8976 | test_loss: 0.2350 | test_acc: 0.9074
Epoch: 24 | train_loss: 0.1586 | train_acc: 0.9360 | val_loss: 0.2619 | val_acc: 0.9009 | test_loss: 0.2294 | test_acc: 0.9104
Epoch: 25 | train_loss: 0.1567 | train_acc: 0.9367 | val_loss: 0.2733 | val_acc: 0.9015 | test_loss: 0.2343 | test_acc: 0.9121
Epoch: 26 | train_loss: 0.1566 | train_acc: 0.9369 | val_loss: 0.2505 | val_acc: 0.9036 | test_loss: 0.2232 | test_acc: 0.9113
Epoch: 27 | train_loss: 0.1551 | train_acc: 0.9374 | val_loss: 0.2619 | val_acc: 0.9064 | test_loss: 0.2314 | test_acc: 0.9119
Epoch: 28 | train_loss: 0.1540 | train_acc: 0.9377 | val_loss: 0.2645 | val_acc: 0.9021 | test_loss: 0.2290 | test_acc: 0.9106
Epoch: 29 | train_loss: 0.1527 | train_acc: 0.9381 | val_loss: 0.2659 | val_acc: 0.9008 | test_loss: 0.2329 | test_acc: 0.9108
Epoch: 30 | train_loss: 0.1513 | train_acc: 0.9391 | val_loss: 0.2972 | val_acc: 0.9023 | test_loss: 0.2462 | test_acc: 0.9136
Epoch: 31 | train_loss: 0.1500 | train_acc: 0.9400 | val_loss: 0.2744 | val_acc: 0.8959 | test_loss: 0.2408 | test_acc: 0.9061
Epoch: 32 | train_loss: 0.1489 | train_acc: 0.9398 | val_loss: 0.2794 | val_acc: 0.8987 | test_loss: 0.2437 | test_acc: 0.9072
Epoch: 33 | train_loss: 0.1473 | train_acc: 0.9406 | val_loss: 0.2782 | val_acc: 0.8981 | test_loss: 0.2365 | test_acc: 0.9100
Epoch: 34 | train_loss: 0.1469 | train_acc: 0.9409 | val_loss: 0.2999 | val_acc: 0.8968 | test_loss: 0.2536 | test_acc: 0.9083
Epoch: 35 | train_loss: 0.1460 | train_acc: 0.9415 | val_loss: 0.2960 | val_acc: 0.8955 | test_loss: 0.2539 | test_acc: 0.9042
Epoch: 36 | train_loss: 0.1446 | train_acc: 0.9421 | val_loss: 0.2860 | val_acc: 0.9049 | test_loss: 0.2452 | test_acc: 0.9115
Epoch: 37 | train_loss: 0.1424 | train_acc: 0.9432 | val_loss: 0.2922 | val_acc: 0.9002 | test_loss: 0.2571 | test_acc: 0.9079
Epoch: 38 | train_loss: 0.1419 | train_acc: 0.9429 | val_loss: 0.2857 | val_acc: 0.9045 | test_loss: 0.2530 | test_acc: 0.9094
Epoch: 39 | train_loss: 0.1403 | train_acc: 0.9440 | val_loss: 0.2835 | val_acc: 0.9036 | test_loss: 0.2522 | test_acc: 0.9051
Epoch: 40 | train_loss: 0.1389 | train_acc: 0.9433 | val_loss: 0.3061 | val_acc: 0.9032 | test_loss: 0.2552 | test_acc: 0.9108
Epoch: 41 | train_loss: 0.1385 | train_acc: 0.9446 | val_loss: 0.2887 | val_acc: 0.9055 | test_loss: 0.2589 | test_acc: 0.9096
Epoch: 42 | train_loss: 0.1367 | train_acc: 0.9450 | val_loss: 0.3145 | val_acc: 0.9024 | test_loss: 0.2662 | test_acc: 0.9091
Epoch: 43 | train_loss: 0.1351 | train_acc: 0.9458 | val_loss: 0.3083 | val_acc: 0.9026 | test_loss: 0.2631 | test_acc: 0.9085
Epoch: 44 | train_loss: 0.1344 | train_acc: 0.9467 | val_loss: 0.3056 | val_acc: 0.9030 | test_loss: 0.2678 | test_acc: 0.9064
Epoch: 45 | train_loss: 0.1331 | train_acc: 0.9453 | val_loss: 0.3061 | val_acc: 0.9062 | test_loss: 0.2665 | test_acc: 0.9098
Epoch: 46 | train_loss: 0.1320 | train_acc: 0.9472 | val_loss: 0.3239 | val_acc: 0.9070 | test_loss: 0.2899 | test_acc: 0.9110
Epoch: 47 | train_loss: 0.1310 | train_acc: 0.9476 | val_loss: 0.3301 | val_acc: 0.9043 | test_loss: 0.2809 | test_acc: 0.9119
Epoch: 48 | train_loss: 0.1295 | train_acc: 0.9481 | val_loss: 0.3064 | val_acc: 0.9000 | test_loss: 0.2644 | test_acc: 0.9085
Epoch: 49 | train_loss: 0.1287 | train_acc: 0.9486 | val_loss: 0.3483 | val_acc: 0.9024 | test_loss: 0.2893 | test_acc: 0.9079
Epoch: 50 | train_loss: 0.1274 | train_acc: 0.9489 | val_loss: 0.3577 | val_acc: 0.8959 | test_loss: 0.3035 | test_acc: 0.9060
[INFO] Saving model to: /var/scratch/ase347/DeepSummit/checkpoints/saint_epochs_50_lr_1e-5_depth_3_dropout_25e-2.pth
