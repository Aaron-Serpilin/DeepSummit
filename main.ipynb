{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Framework for Predicting Himalayan Summit Success \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.6.0\n",
      "torchvision version: 0.21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aaronserpilin/anaconda3/envs/Python3_Env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlextend version: 0.23.4\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    import torchvision\n",
    "    assert int(torch.__version__.split(\".\")[0]) >= 2, \"torch version should be 2.+\"\n",
    "    assert int(torchvision.__version__.split(\".\")[1]) >= 15, \"torchvision version should be 0.15+\"\n",
    "    print(f\"torch version: {torch.__version__}\")\n",
    "    print(f\"torchvision version: {torchvision.__version__}\")\n",
    "except:\n",
    "    print(f\"[INFO] torch/torchvision versions not correct. Installing correct versions.\")\n",
    "    !pip3 install -U torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "    import torch\n",
    "    import torchvision\n",
    "    print(f\"torch version: {torch.__version__}\")\n",
    "    print(f\"torchvision version: {torchvision.__version__}\")\n",
    "\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "except ImportError:\n",
    "    print(\"[INFO] Couldn't find matplotlib...installing it\")\n",
    "    !pip install -q matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    from torchinfo import summary\n",
    "except:\n",
    "    print(\"[INFO] Couldn't find torchinfo... installing it\")\n",
    "    !pip install -q torchinfo\n",
    "    from torchinfo import summary\n",
    "\n",
    "try:\n",
    "    from tqdm.auto import tqdm\n",
    "except:\n",
    "    print(f\"[INFO] Couldnt't find tqdm... installing it \")\n",
    "    !pip install tqdm\n",
    "    from tqdm.auto import tqdm\n",
    "\n",
    "try:\n",
    "    from torchinfo import summary\n",
    "except ImportError:\n",
    "    print(\"[INFO] Couldn't find torchinfo... installing it\")\n",
    "    !pip install -q torchinfo\n",
    "    from torchinfo import summary\n",
    "\n",
    "try:\n",
    "    from dbfread import DBF\n",
    "except ImportError:\n",
    "    print(\"[INFO] Coudln't find dbfread...installing it\")\n",
    "    !pip install -q dbfread\n",
    "    from dbfread import DBF\n",
    "\n",
    "\n",
    "try:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "except:\n",
    "    print(\"[INFO] Couldn't find tensorboard... installing it.\")\n",
    "    !pip install -q tensorboard\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "try:\n",
    "    import torchmetrics, mlxtend\n",
    "    print(f\"mlextend version: {mlxtend.__version__}\")\n",
    "    assert int(mlxtend.__version__.split(\".\")[1]) >- 19\n",
    "except:\n",
    "    !pip install -q torchmetrics -U mlxtend\n",
    "    import torchmetrics, mlxtend\n",
    "    print(f\"mlextend version: {mlxtend.__version__}\")\n",
    "\n",
    "try:\n",
    "    import cdsapi\n",
    "except ImportError:\n",
    "    print(\"[INFO] Coudldn't find cdsapi...installing it.\")\n",
    "    !pip install -q cdsapi\n",
    "    import cdsapi\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "except ImportError:\n",
    "    print(\"[INFO] Couldn't find pandas... installing it\")\n",
    "    !pip install -q pandas\n",
    "    import pandas as pd\n",
    "\n",
    "try:\n",
    "    from einops import rearrange, repeat\n",
    "except ImportError:\n",
    "    print(\"[INFO] Couldn't find einops... installing it\")\n",
    "    !pip install -q einops\n",
    "    from einops import rearrange, repeat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We adjust the PYTHONPATH to keep absolute imports\n",
    "import sys\n",
    "sys.path.append(\"src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "himalayan_train_dir = Path(\"data/himalayas_data/train\")\n",
    "himalayan_val_dir = Path(\"data/himalayas_data/val\")\n",
    "himalayan_test_dir = Path(\"data/himalayas_data/test\")\n",
    "\n",
    "himalayan_train_file = himalayan_train_dir / \"train.csv\"\n",
    "himalayan_val_file = himalayan_val_dir / \"val.csv\"\n",
    "himalayan_test_file = himalayan_test_dir / \"test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 rows:\n",
      "  SEX      CITIZEN      STATUS  MO2USED  MROUTE1  SEASON  O2USED  CALCAGE  \\\n",
      "0   M        Japan     Climber     True        1       3    True       49   \n",
      "1   M        Spain     Climber    False        1       3   False       54   \n",
      "2   F  Switzerland     Climber    False        1       3    True       25   \n",
      "3   M        Nepal  H-A Worker     True        1       1    True       31   \n",
      "4   M          USA     Climber     True        1       1    True       60   \n",
      "5   M      Bahrain     Climber    False        1       3    True       34   \n",
      "6   M        Chile     Climber     True        1       1    True       42   \n",
      "7   F        Japan      Leader     True        0       4    True       43   \n",
      "8   M        India     Climber     True        1       1    True       48   \n",
      "9   M      S Korea     Climber    False        0       3   False       29   \n",
      "\n",
      "   HEIGHTM  MDEATHS  HDEATHS  SMTMEMBERS  SMTHIRED  Target  \n",
      "0     8163        0        0          14        11       1  \n",
      "1     8163        0        0           1         1       0  \n",
      "2     8485        0        0           1         0       0  \n",
      "3     8849        0        0           0         9       1  \n",
      "4     8188        0        0           6         3       1  \n",
      "5     8163        0        0          13        43       1  \n",
      "6     8849        0        0           0         0       0  \n",
      "7     8849        0        0           0         0       0  \n",
      "8     8849        0        0           8        11       1  \n",
      "9     8188        0        0           5         1       0  \n",
      "First training instance:\n",
      "SEX                 M\n",
      "CITIZEN         Japan\n",
      "STATUS        Climber\n",
      "MO2USED          True\n",
      "MROUTE1             1\n",
      "SEASON              3\n",
      "O2USED           True\n",
      "CALCAGE            49\n",
      "HEIGHTM          8163\n",
      "MDEATHS             0\n",
      "HDEATHS             0\n",
      "SMTMEMBERS         14\n",
      "SMTHIRED           11\n",
      "Target              1\n",
      "Name: 0, dtype: object\n",
      "Instance shape:\n",
      "(14,)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(himalayan_train_file)\n",
    "\n",
    "print(f\"First 10 rows:\\n{df_train.head(10)}\")\n",
    "print(f\"First training instance:\\n{df_train.iloc[0]}\")\n",
    "print(f\"Instance shape:\\n{df_train.iloc[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training set saved to: data/himalayas_data/train/train.csv\n",
      "[INFO] Validation set saved to: data/himalayas_data/val/val.csv\n",
      "[INFO] Test set saved to: data/himalayas_data/test/test.csv\n",
      "[INFO] Himalaya Data has already been processed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x31b242910>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x31b27a310>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x31b240690>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.data_setup import train_dataloader, val_dataloader, test_dataloader\n",
    "\n",
    "train_dataloader, val_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical instance: tensor([  0,   1, 147,  60,   0,   1,   2,   0])\n",
      "Categorical instance shape: torch.Size([8])\n",
      "\n",
      "Continuous instance: tensor([ 0.2272, -1.1185, -0.2801, -0.1664, -0.8072, -0.6175])\n",
      "Continuous instance shape: torch.Size([6])\n",
      "\n",
      "Label instance: 0\n",
      "Label instance shape: torch.Size([])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat_batch, cont_batch, label_batch, cat_mask_batch, cont_mask_batch = next(iter(train_dataloader))\n",
    "\n",
    "# First instance\n",
    "cat_instance = cat_batch[0]\n",
    "cont_instance = cont_batch[0]\n",
    "label_instance = label_batch[0]\n",
    "\n",
    "print(f\"Categorical instance: {cat_instance}\\nCategorical instance shape: {cat_instance.shape}\\n\")\n",
    "print(f\"Continuous instance: {cont_instance}\\nContinuous instance shape: {cont_instance.shape}\\n\")\n",
    "print(f\"Label instance: {label_instance}\\nLabel instance shape: {label_instance.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tab_transformer.tab_model import SAINT\n",
    "from src.data_setup import continuous_columns, categorical_columns\n",
    "import numpy as np\n",
    "\n",
    "# Returns the amount of unique values per categorical column\n",
    "cat_dims = [len(np.unique(df_train[col])) for col in categorical_columns]\n",
    "\n",
    "# Hyperparameter selection based on default original architecture instantiation\n",
    "saint = SAINT(\n",
    "    categories = tuple(cat_dims), \n",
    "    num_continuous = len(continuous_columns),                \n",
    "    dim = 32,                           \n",
    "    dim_out = 1,                       \n",
    "    depth = 6,                       \n",
    "    heads = 8,                         \n",
    "    attn_dropout = 0.1,             \n",
    "    ff_dropout = 0.1,                  \n",
    "    mlp_hidden_mults = (4, 2),       \n",
    "    cont_embeddings = 'MLP',\n",
    "    attentiontype = 'colrow',\n",
    "    final_mlp_style = 'sep',\n",
    "    y_dim = 2 # Binary classification\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchinfo import summary\n",
    "# import torch\n",
    "\n",
    "# summary(model=model,\n",
    "#         # input_size=[(32, 8, 32), (32, 6, 32)],\n",
    "#         input_size=(416, 13),\n",
    "#         dtypes=[torch.float, torch.float],\n",
    "#         col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "#         col_width=20,\n",
    "#         row_settings=[\"var_names\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offsets are: tensor([  0,   3, 218, 590, 592, 597, 601])\n",
      "\n",
      "[INFO] x_categ before: tensor([[  0,   1,  77,  60,   0,   0,   0,   1],\n",
      "        [  0,   1, 104, 230,   1,   1,   0,   1],\n",
      "        [  0,   1,  76,  60,   0,   1,   0,   1],\n",
      "        [  0,   0,  66,  60,   0,   1,   0,   0],\n",
      "        [  0,   0, 121,  60,   0,   1,   0,   1],\n",
      "        [  0,   1, 104, 230,   1,   1,   0,   1],\n",
      "        [  0,   1,  32, 224,   1,   1,   0,   1],\n",
      "        [  0,   1, 153,  60,   0,   0,   2,   0],\n",
      "        [  0,   1,  32, 129,   0,   0,   0,   1],\n",
      "        [  0,   1, 153,  60,   0,   0,   0,   0],\n",
      "        [  0,   1, 136,  60,   0,   1,   0,   1],\n",
      "        [  0,   1, 104, 230,   1,   1,   2,   1],\n",
      "        [  0,   1,  76,  60,   0,   1,   2,   0],\n",
      "        [  0,   1, 111, 253,   1,   1,   0,   1],\n",
      "        [  0,   1, 104, 230,   0,   1,   2,   0],\n",
      "        [  0,   1, 153, 167,   0,   1,   0,   0],\n",
      "        [  0,   1, 183,  60,   1,   1,   0,   1],\n",
      "        [  0,   1, 166,  60,   1,   1,   2,   1],\n",
      "        [  0,   1,  32, 224,   1,   1,   0,   1],\n",
      "        [  0,   0,  32,  60,   1,   1,   2,   1],\n",
      "        [  0,   1,  18,  60,   1,   1,   0,   1],\n",
      "        [  0,   1,  96,  60,   1,   1,   0,   1],\n",
      "        [  0,   1,  77, 137,   1,   1,   0,   1],\n",
      "        [  0,   1,   7,  60,   1,   1,   2,   1],\n",
      "        [  0,   1,  32, 137,   0,   0,   2,   1],\n",
      "        [  0,   1,  96,  60,   0,   1,   0,   0],\n",
      "        [  0,   0,  43,  60,   0,   0,   2,   0],\n",
      "        [  0,   1, 166,  60,   1,   1,   0,   1],\n",
      "        [  0,   1, 104, 230,   1,   1,   2,   1],\n",
      "        [  0,   0, 183, 181,   0,   1,   2,   1],\n",
      "        [  0,   1, 104, 230,   1,   1,   0,   1],\n",
      "        [  0,   0,  54,  60,   0,   1,   0,   1]])\n",
      "Size before: torch.Size([32, 8])\n",
      "\n",
      "[INFO] x_categ after: tensor([[  0,   1,  80, 278, 590, 592, 597, 602],\n",
      "        [  0,   1, 107, 448, 591, 593, 597, 602],\n",
      "        [  0,   1,  79, 278, 590, 593, 597, 602],\n",
      "        [  0,   0,  69, 278, 590, 593, 597, 601],\n",
      "        [  0,   0, 124, 278, 590, 593, 597, 602],\n",
      "        [  0,   1, 107, 448, 591, 593, 597, 602],\n",
      "        [  0,   1,  35, 442, 591, 593, 597, 602],\n",
      "        [  0,   1, 156, 278, 590, 592, 599, 601],\n",
      "        [  0,   1,  35, 347, 590, 592, 597, 602],\n",
      "        [  0,   1, 156, 278, 590, 592, 597, 601],\n",
      "        [  0,   1, 139, 278, 590, 593, 597, 602],\n",
      "        [  0,   1, 107, 448, 591, 593, 599, 602],\n",
      "        [  0,   1,  79, 278, 590, 593, 599, 601],\n",
      "        [  0,   1, 114, 471, 591, 593, 597, 602],\n",
      "        [  0,   1, 107, 448, 590, 593, 599, 601],\n",
      "        [  0,   1, 156, 385, 590, 593, 597, 601],\n",
      "        [  0,   1, 186, 278, 591, 593, 597, 602],\n",
      "        [  0,   1, 169, 278, 591, 593, 599, 602],\n",
      "        [  0,   1,  35, 442, 591, 593, 597, 602],\n",
      "        [  0,   0,  35, 278, 591, 593, 599, 602],\n",
      "        [  0,   1,  21, 278, 591, 593, 597, 602],\n",
      "        [  0,   1,  99, 278, 591, 593, 597, 602],\n",
      "        [  0,   1,  80, 355, 591, 593, 597, 602],\n",
      "        [  0,   1,  10, 278, 591, 593, 599, 602],\n",
      "        [  0,   1,  35, 355, 590, 592, 599, 602],\n",
      "        [  0,   1,  99, 278, 590, 593, 597, 601],\n",
      "        [  0,   0,  46, 278, 590, 592, 599, 601],\n",
      "        [  0,   1, 169, 278, 591, 593, 597, 602],\n",
      "        [  0,   1, 107, 448, 591, 593, 599, 602],\n",
      "        [  0,   0, 186, 399, 590, 593, 599, 602],\n",
      "        [  0,   1, 107, 448, 591, 593, 597, 602],\n",
      "        [  0,   0,  57, 278, 590, 593, 597, 602]])\n",
      "Size after: torch.Size([32, 8])\n",
      "\n",
      "[INFO] x_cont_enc: tensor([[[-3.0457e-01, -4.5900e-01, -5.4255e-03,  ...,  6.3248e-02,\n",
      "          -2.5137e-01, -1.6328e-01],\n",
      "         [-2.6481e-01, -1.0698e-01,  3.1727e-01,  ...,  2.7950e-02,\n",
      "           8.9442e-02, -2.0919e-01],\n",
      "         [-2.0995e-01,  3.3324e-02,  5.7076e-02,  ..., -1.0405e-01,\n",
      "           4.6612e-02, -3.9005e-01],\n",
      "         [-2.2223e-01, -1.7964e-01, -2.0817e-02,  ..., -4.6108e-02,\n",
      "          -9.5507e-02, -3.9433e-01],\n",
      "         [ 4.5078e-01,  1.6421e-01,  6.3069e-02,  ...,  2.3355e-01,\n",
      "          -1.0283e-01,  1.9476e-01],\n",
      "         [-2.1642e-01,  6.9751e-02, -5.1339e-02,  ...,  1.1129e-01,\n",
      "          -1.9716e-01,  6.6001e-02]],\n",
      "\n",
      "        [[-2.5239e-01, -3.1237e-02,  3.1768e-01,  ..., -1.2321e-02,\n",
      "           1.0737e-01,  1.0428e-01],\n",
      "         [-2.6481e-01, -1.0698e-01,  3.1727e-01,  ...,  2.7950e-02,\n",
      "           8.9442e-02, -2.0919e-01],\n",
      "         [-6.0509e-01, -4.3749e-01,  5.4996e-01,  ..., -8.3115e-02,\n",
      "          -2.3463e-01, -6.5691e-01],\n",
      "         [-2.2223e-01, -1.7964e-01, -2.0817e-02,  ..., -4.6108e-02,\n",
      "          -9.5507e-02, -3.9433e-01],\n",
      "         [ 2.0702e-01,  4.5038e-01, -4.5922e-01,  ..., -1.0735e-01,\n",
      "          -4.8127e-02,  3.1035e-01],\n",
      "         [-7.2018e-01, -4.2148e-01, -3.7704e-01,  ...,  4.8338e-02,\n",
      "          -1.0875e-01, -2.0279e-01]],\n",
      "\n",
      "        [[-2.4196e-01, -2.9747e-01,  3.1067e-02,  ...,  1.8149e-03,\n",
      "          -9.1845e-02, -1.2030e-01],\n",
      "         [-2.6481e-01, -1.0698e-01,  3.1727e-01,  ...,  2.7950e-02,\n",
      "           8.9442e-02, -2.0919e-01],\n",
      "         [-2.0995e-01,  3.3324e-02,  5.7076e-02,  ..., -1.0405e-01,\n",
      "           4.6612e-02, -3.9005e-01],\n",
      "         [-2.2223e-01, -1.7964e-01, -2.0817e-02,  ..., -4.6108e-02,\n",
      "          -9.5507e-02, -3.9433e-01],\n",
      "         [ 4.0367e-01,  1.7119e-01, -1.1267e-02,  ...,  1.5951e-01,\n",
      "          -6.0995e-02,  2.0869e-01],\n",
      "         [-2.1642e-01,  6.9751e-02, -5.1339e-02,  ...,  1.1129e-01,\n",
      "          -1.9716e-01,  6.6001e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.9892e-01, -1.3157e-01,  1.1826e-01,  ..., -2.7997e-02,\n",
      "           5.8571e-04, -4.5174e-02],\n",
      "         [-2.6481e-01, -1.0698e-01,  3.1727e-01,  ...,  2.7950e-02,\n",
      "           8.9442e-02, -2.0919e-01],\n",
      "         [-2.0995e-01,  3.3324e-02,  5.7076e-02,  ..., -1.0405e-01,\n",
      "           4.6612e-02, -3.9005e-01],\n",
      "         [-2.2223e-01, -1.7964e-01, -2.0817e-02,  ..., -4.6108e-02,\n",
      "          -9.5507e-02, -3.9433e-01],\n",
      "         [ 4.5078e-01,  1.6421e-01,  6.3069e-02,  ...,  2.3355e-01,\n",
      "          -1.0283e-01,  1.9476e-01],\n",
      "         [-2.1642e-01,  6.9751e-02, -5.1339e-02,  ...,  1.1129e-01,\n",
      "          -1.9716e-01,  6.6001e-02]],\n",
      "\n",
      "        [[-2.4384e-01, -2.5590e-01,  3.2948e-02,  ..., -8.2463e-03,\n",
      "          -7.0639e-02, -1.1032e-01],\n",
      "         [-2.6481e-01, -1.0698e-01,  3.1727e-01,  ...,  2.7950e-02,\n",
      "           8.9442e-02, -2.0919e-01],\n",
      "         [-2.0995e-01,  3.3324e-02,  5.7076e-02,  ..., -1.0405e-01,\n",
      "           4.6612e-02, -3.9005e-01],\n",
      "         [-2.2223e-01, -1.7964e-01, -2.0817e-02,  ..., -4.6108e-02,\n",
      "          -9.5507e-02, -3.9433e-01],\n",
      "         [ 3.9562e-01,  2.0290e-01, -6.2924e-02,  ...,  1.1210e-01,\n",
      "          -5.1437e-02,  2.2501e-01],\n",
      "         [-2.5588e-01,  3.3506e-02, -1.2981e-01,  ...,  6.5175e-02,\n",
      "          -1.9174e-01, -3.2011e-02]],\n",
      "\n",
      "        [[-2.2816e-01, -4.7230e-02,  2.5705e-01,  ..., -4.1699e-02,\n",
      "           1.0169e-01,  6.4724e-02],\n",
      "         [-2.6481e-01, -1.0698e-01,  3.1727e-01,  ...,  2.7950e-02,\n",
      "           8.9442e-02, -2.0919e-01],\n",
      "         [-2.0995e-01,  3.3324e-02,  5.7076e-02,  ..., -1.0405e-01,\n",
      "           4.6612e-02, -3.9005e-01],\n",
      "         [-2.2223e-01, -1.7964e-01, -2.0817e-02,  ..., -4.6108e-02,\n",
      "          -9.5507e-02, -3.9433e-01],\n",
      "         [ 4.5078e-01,  1.6421e-01,  6.3069e-02,  ...,  2.3355e-01,\n",
      "          -1.0283e-01,  1.9476e-01],\n",
      "         [-2.1642e-01,  6.9751e-02, -5.1339e-02,  ...,  1.1129e-01,\n",
      "          -1.9716e-01,  6.6001e-02]]], grad_fn=<CopySlices>)\n",
      "x_cont_enc shape: torch.Size([32, 6, 32])\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given normalized_shape=[416], expected input with shape [*, 416], but got input of size[1, 32, 448]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m loss_fn = nn.CrossEntropyLoss().to(device)\n\u001b[32m      4\u001b[39m optimizer = torch.optim.AdamW(saint.parameters(),lr=\u001b[32m0.0001\u001b[39m, betas=(\u001b[32m0.9\u001b[39m, \u001b[32m0.999\u001b[39m), weight_decay=\u001b[32m0.01\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43msaint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m           \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m           \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m           \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m           \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m           \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Extra-Programming-Courses/Pytorch-Projects/DeepSummit/src/tab_transformer/tab_train.py:48\u001b[39m, in \u001b[36mtrain_step\u001b[39m\u001b[34m(model, dataloader, loss_fn, optimizer, device)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# print(f\"x_categ: {x_categ}\\nx_cont: {x_cont}\\ny_gts: {y_gts}\\ncat_mask:{cat_mask}\\ncon_mask:{con_mask}\\n\")\u001b[39;00m\n\u001b[32m     47\u001b[39m _, x_categ_enc, x_cont_enc = embed_data_mask(x_categ, x_cont, cat_mask, con_mask,model, \u001b[38;5;28;01mFalse\u001b[39;00m)  \n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m reps = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_categ_enc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_cont_enc\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/Python3_Env/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/Python3_Env/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Extra-Programming-Courses/Pytorch-Projects/DeepSummit/src/tab_transformer/tab_attention.py:247\u001b[39m, in \u001b[36mRowColTransformer.forward\u001b[39m\u001b[34m(self, x, x_cont, mask)\u001b[39m\n\u001b[32m    245\u001b[39m x = ff1(x)\n\u001b[32m    246\u001b[39m x = rearrange(x, \u001b[33m'\u001b[39m\u001b[33mb n d -> 1 b (n d)\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m x = \u001b[43mattn2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    248\u001b[39m x = ff2(x)\n\u001b[32m    249\u001b[39m x = rearrange(x, \u001b[33m'\u001b[39m\u001b[33m1 b (n d) -> b n d\u001b[39m\u001b[33m'\u001b[39m, n = n)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/Python3_Env/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/Python3_Env/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Extra-Programming-Courses/Pytorch-Projects/DeepSummit/src/tab_transformer/tab_blocks.py:105\u001b[39m, in \u001b[36mPreNorm.forward\u001b[39m\u001b[34m(self, x, **kwargs)\u001b[39m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m (\u001b[38;5;28mself\u001b[39m, x, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fn(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/Python3_Env/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/Python3_Env/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/Python3_Env/lib/python3.11/site-packages/torch/nn/modules/normalization.py:217\u001b[39m, in \u001b[36mLayerNorm.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meps\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/Python3_Env/lib/python3.11/site-packages/torch/nn/functional.py:2910\u001b[39m, in \u001b[36mlayer_norm\u001b[39m\u001b[34m(input, normalized_shape, weight, bias, eps)\u001b[39m\n\u001b[32m   2900\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[32m   2901\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m   2902\u001b[39m         layer_norm,\n\u001b[32m   2903\u001b[39m         (\u001b[38;5;28minput\u001b[39m, weight, bias),\n\u001b[32m   (...)\u001b[39m\u001b[32m   2908\u001b[39m         eps=eps,\n\u001b[32m   2909\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2910\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2911\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackends\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcudnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43menabled\u001b[49m\n\u001b[32m   2912\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Given normalized_shape=[416], expected input with shape [*, 416], but got input of size[1, 32, 448]"
     ]
    }
   ],
   "source": [
    "from src.tab_transformer.tab_train import train_step\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.AdamW(saint.parameters(),lr=0.0001, betas=(0.9, 0.999), weight_decay=0.01)\n",
    "\n",
    "train_step(model=saint,\n",
    "           dataloader=train_dataloader,\n",
    "           loss_fn=loss_fn,\n",
    "           optimizer=optimizer,\n",
    "           device=device\n",
    "           )\n",
    "                              "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
