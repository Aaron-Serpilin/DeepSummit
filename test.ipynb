{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ed3c837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.6.0\n",
      "torchvision version: 0.21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aaronserpilin/anaconda3/envs/Python3_Env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlextend version: 0.23.4\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    import torchvision\n",
    "    assert int(torch.__version__.split(\".\")[0]) >= 2, \"torch version should be 2.+\"\n",
    "    assert int(torchvision.__version__.split(\".\")[1]) >= 15, \"torchvision version should be 0.15+\"\n",
    "    print(f\"torch version: {torch.__version__}\")\n",
    "    print(f\"torchvision version: {torchvision.__version__}\")\n",
    "except:\n",
    "    print(f\"[INFO] torch/torchvision versions not correct. Installing correct versions.\")\n",
    "    !pip3 install -U torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "    import torch\n",
    "    import torchvision\n",
    "    print(f\"torch version: {torch.__version__}\")\n",
    "    print(f\"torchvision version: {torchvision.__version__}\")\n",
    "\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "except ImportError:\n",
    "    print(\"[INFO] Couldn't find matplotlib...installing it\")\n",
    "    !pip install -q matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    from torchinfo import summary\n",
    "except:\n",
    "    print(\"[INFO] Couldn't find torchinfo... installing it\")\n",
    "    !pip install -q torchinfo\n",
    "    from torchinfo import summary\n",
    "\n",
    "try:\n",
    "    from tqdm.auto import tqdm\n",
    "except:\n",
    "    print(f\"[INFO] Couldnt't find tqdm... installing it \")\n",
    "    !pip install tqdm\n",
    "    from tqdm.auto import tqdm\n",
    "\n",
    "try:\n",
    "    from torchinfo import summary\n",
    "except ImportError:\n",
    "    print(\"[INFO] Couldn't find torchinfo... installing it\")\n",
    "    !pip install -q torchinfo\n",
    "    from torchinfo import summary\n",
    "\n",
    "try:\n",
    "    from dbfread import DBF\n",
    "except ImportError:\n",
    "    print(\"[INFO] Coudln't find dbfread...installing it\")\n",
    "    !pip install -q dbfread\n",
    "    from dbfread import DBF\n",
    "\n",
    "\n",
    "try:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "except:\n",
    "    print(\"[INFO] Couldn't find tensorboard... installing it.\")\n",
    "    !pip install -q tensorboard\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "try:\n",
    "    import torchmetrics, mlxtend\n",
    "    print(f\"mlextend version: {mlxtend.__version__}\")\n",
    "    assert int(mlxtend.__version__.split(\".\")[1]) >- 19\n",
    "except:\n",
    "    !pip install -q torchmetrics -U mlxtend\n",
    "    import torchmetrics, mlxtend\n",
    "    print(f\"mlextend version: {mlxtend.__version__}\")\n",
    "\n",
    "try:\n",
    "    import cdsapi\n",
    "except ImportError:\n",
    "    print(\"[INFO] Coudldn't find cdsapi...installing it.\")\n",
    "    !pip install -q cdsapi\n",
    "    import cdsapi\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "except ImportError:\n",
    "    print(\"[INFO] Couldn't find pandas... installing it\")\n",
    "    !pip install -q pandas\n",
    "    import pandas as pd\n",
    "\n",
    "try:\n",
    "    from einops import rearrange, repeat\n",
    "except ImportError:\n",
    "    print(\"[INFO] Couldn't find einops... installing it\")\n",
    "    !pip install -q einops\n",
    "    from einops import rearrange, repeat\n",
    "\n",
    "try:\n",
    "    import pygrib\n",
    "except ImportError:\n",
    "    print(\"[INFO] Couldn't find pygrib... installing it\")\n",
    "    !pip install -q pygrib\n",
    "    import pygrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "940af7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"src\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# weather_mapping = {\n",
    "#     '10u':   '10 metre U wind component',\n",
    "#     '10v':   '10 metre V wind component',\n",
    "#     '2d':    '2 metre dewpoint temperature',\n",
    "#     '2t':    '2 metre temperature',\n",
    "#     'msl':   'Mean sea level pressure',\n",
    "#     'sst':   'Sea surface temperature',\n",
    "#     'sp':    'Surface pressure',\n",
    "#     'tp':    'Total precipitation',\n",
    "#     'istl1': 'Ice temperature layer 1',\n",
    "#     'istl2': 'Ice temperature layer 2',\n",
    "#     'istl3': 'Ice temperature layer 3',\n",
    "#     'istl4': 'Ice temperature layer 4',\n",
    "#     'mx2t':  'Maximum temperature at 2 metres since previous post-processing',\n",
    "#     'mn2t':  'Minimum temperature at 2 metres since previous post-processing',\n",
    "#     'skt':   'Skin temperature',\n",
    "#     '100u':  '100 metre U wind component',\n",
    "#     '100v':  '100 metre V wind component',\n",
    "#     'u10n':  '10 metre u-component of neutral wind',\n",
    "#     'v10n':  '10 metre v-component of neutral wind',\n",
    "#     '10fg':  'Maximum 10 metre wind gust since previous post-processing',\n",
    "#     'i10fg': 'Instantaneous 10 metre wind gust',\n",
    "#     'cbh':   'Cloud base height',\n",
    "#     'hcc':   'High cloud cover',\n",
    "#     'lcc':   'Low cloud cover',\n",
    "#     'mcc':   'Medium cloud cover',\n",
    "#     'tcc':   'Total cloud cover',\n",
    "#     'tciw':  'Total column cloud ice water',\n",
    "#     'tclw':  'Total column cloud liquid water',\n",
    "#     'viiwd': 'Vertical integral of divergence of cloud frozen water flux',\n",
    "#     'vilwd': 'Vertical integral of divergence of cloud liquid water flux',\n",
    "#     'viiwe': 'Vertical integral of eastward cloud frozen water flux',\n",
    "#     'vilwe': 'Vertical integral of eastward cloud liquid water flux',\n",
    "#     'viiwn': 'Vertical integral of northward cloud frozen water flux',\n",
    "#     'vilwn': 'Vertical integral of northward cloud liquid water flux',\n",
    "#     'cp':    'Convective precipitation',\n",
    "#     'crr':   'Convective rain rate',\n",
    "#     'ilspf': 'Instantaneous large-scale surface precipitation fraction',\n",
    "#     'lsrr':  'Large scale rain rate',\n",
    "#     'lsp':   'Large-scale precipitation',\n",
    "#     'lspf':  'Large-scale precipitation fraction',\n",
    "#     'mxtpr': 'Maximum total precipitation rate since previous post-processing',\n",
    "#     'mntpr': 'Minimum total precipitation rate since previous post-processing',\n",
    "#     'ptype': 'Precipitation type',\n",
    "#     'tcrw':  'Total column rain water',\n",
    "#     'csf':   'Convective snowfall',\n",
    "#     'csfr':  'Convective snowfall rate water equivalent',\n",
    "#     'lssfr': 'Large scale snowfall rate water equivalent',\n",
    "#     'lsf':   'Large-scale snowfall',\n",
    "#     'asn':   'Snow albedo',\n",
    "#     'rsn':   'Snow density',\n",
    "#     'sd':    'Snow depth',\n",
    "#     'es':    'Snow evaporation',\n",
    "#     'sf':    'Snowfall',\n",
    "#     'smlt':  'Snowmelt',\n",
    "#     'tsn':   'Temperature of snow layer',\n",
    "#     'tcsw':  'Total column snow water'\n",
    "# }\n",
    "\n",
    "weather_mapping = {\n",
    "    '10u':   '10 metre U wind component',\n",
    "    '10v':   '10 metre V wind component',\n",
    "    '2d':    '2 metre dewpoint temperature',\n",
    "    '2t':    '2 metre temperature',\n",
    "    'msl':   'Mean sea level pressure',\n",
    "    'sp':    'Surface pressure',\n",
    "    'tp':    'Total precipitation',\n",
    "    'istl1': 'Ice temperature layer 1',\n",
    "    'istl2': 'Ice temperature layer 2',\n",
    "    'istl3': 'Ice temperature layer 3',\n",
    "    'istl4': 'Ice temperature layer 4',\n",
    "    'mx2t':  'Maximum temperature at 2 metres since previous post-processing',\n",
    "    'mn2t':  'Minimum temperature at 2 metres since previous post-processing',\n",
    "    'skt':   'Skin temperature',\n",
    "    '100u':  '100 metre U wind component',\n",
    "    '100v':  '100 metre V wind component',\n",
    "    'u10n':  '10 metre u-component of neutral wind',\n",
    "    'v10n':  '10 metre v-component of neutral wind',\n",
    "    '10fg':  'Maximum 10 metre wind gust since previous post-processing',\n",
    "    'i10fg': 'Instantaneous 10 metre wind gust',\n",
    "    'cbh':   'Cloud base height',\n",
    "    'hcc':   'High cloud cover',\n",
    "    'lcc':   'Low cloud cover',\n",
    "    'mcc':   'Medium cloud cover',\n",
    "    'tcc':   'Total cloud cover',\n",
    "    'tciw':  'Total column cloud ice water',\n",
    "    'tclw':  'Total column cloud liquid water',\n",
    "    'viiwd': 'Vertical integral of divergence of cloud frozen water flux',\n",
    "    'vilwd': 'Vertical integral of divergence of cloud liquid water flux',\n",
    "    'viiwe': 'Vertical integral of eastward cloud frozen water flux',\n",
    "    'vilwe': 'Vertical integral of eastward cloud liquid water flux',\n",
    "    'viiwn': 'Vertical integral of northward cloud frozen water flux',\n",
    "    'vilwn': 'Vertical integral of northward cloud liquid water flux',\n",
    "    'cp':    'Convective precipitation',\n",
    "    'crr':   'Convective rain rate',\n",
    "    'ilspf': 'Instantaneous large-scale surface precipitation fraction',\n",
    "    'lsrr':  'Large scale rain rate',\n",
    "    'lsp':   'Large-scale precipitation',\n",
    "    'lspf':  'Large-scale precipitation fraction',\n",
    "    'mxtpr': 'Maximum total precipitation rate since previous post-processing',\n",
    "    'mntpr': 'Minimum total precipitation rate since previous post-processing',\n",
    "    'ptype': 'Precipitation type',\n",
    "    'tcrw':  'Total column rain water',\n",
    "    'csf':   'Convective snowfall',\n",
    "    'csfr':  'Convective snowfall rate water equivalent',\n",
    "    'lssfr': 'Large scale snowfall rate water equivalent',\n",
    "    'lsf':   'Large-scale snowfall',\n",
    "    'asn':   'Snow albedo',\n",
    "    'rsn':   'Snow density',\n",
    "    'sd':    'Snow depth',\n",
    "    'es':    'Snow evaporation',\n",
    "    'sf':    'Snowfall',\n",
    "    'smlt':  'Snowmelt',\n",
    "    'tsn':   'Temperature of snow layer',\n",
    "    'tcsw':  'Total column snow water'\n",
    "}\n",
    "\n",
    "met_weights = {\n",
    "    key: 1.2 # an 20% boost to these key weights\n",
    "    for key, description in weather_mapping.items()\n",
    "    if any(term in description.lower() for term in (\"wind\", \"temperature\", \"pressure\"))\n",
    "}\n",
    "\n",
    "priority_features = [key for key in met_weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fc20cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables = [\n",
    "#         \"10m_u_component_of_wind\",\n",
    "#         \"10m_v_component_of_wind\",\n",
    "#         \"2m_dewpoint_temperature\",\n",
    "#         \"2m_temperature\",\n",
    "#         \"mean_sea_level_pressure\",\n",
    "#         \"sea_surface_temperature\",\n",
    "#         \"surface_pressure\",\n",
    "#         \"total_precipitation\",\n",
    "#         \"ice_temperature_layer_1\",\n",
    "#         \"ice_temperature_layer_2\",\n",
    "#         \"ice_temperature_layer_3\",\n",
    "#         \"ice_temperature_layer_4\",\n",
    "#         \"maximum_2m_temperature_since_previous_post_processing\",\n",
    "#         \"minimum_2m_temperature_since_previous_post_processing\",\n",
    "#         \"skin_temperature\",\n",
    "#         \"100m_u_component_of_wind\",\n",
    "#         \"100m_v_component_of_wind\",\n",
    "#         \"10m_u_component_of_neutral_wind\",\n",
    "#         \"10m_v_component_of_neutral_wind\",\n",
    "#         \"10m_wind_gust_since_previous_post_processing\",\n",
    "#         \"instantaneous_10m_wind_gust\",\n",
    "#         \"cloud_base_height\",\n",
    "#         \"high_cloud_cover\",\n",
    "#         \"low_cloud_cover\",\n",
    "#         \"medium_cloud_cover\",\n",
    "#         \"total_cloud_cover\",\n",
    "#         \"total_column_cloud_ice_water\",\n",
    "#         \"total_column_cloud_liquid_water\",\n",
    "#         \"vertical_integral_of_divergence_of_cloud_frozen_water_flux\",\n",
    "#         \"vertical_integral_of_divergence_of_cloud_liquid_water_flux\",\n",
    "#         \"vertical_integral_of_eastward_cloud_frozen_water_flux\",\n",
    "#         \"vertical_integral_of_eastward_cloud_liquid_water_flux\",\n",
    "#         \"vertical_integral_of_northward_cloud_frozen_water_flux\",\n",
    "#         \"vertical_integral_of_northward_cloud_liquid_water_flux\",\n",
    "#         \"convective_precipitation\",\n",
    "#         \"convective_rain_rate\",\n",
    "#         \"instantaneous_large_scale_surface_precipitation_fraction\",\n",
    "#         \"large_scale_rain_rate\",\n",
    "#         \"large_scale_precipitation\",\n",
    "#         \"large_scale_precipitation_fraction\",\n",
    "#         \"maximum_total_precipitation_rate_since_previous_post_processing\",\n",
    "#         \"minimum_total_precipitation_rate_since_previous_post_processing\",\n",
    "#         \"precipitation_type\",\n",
    "#         \"total_column_rain_water\",\n",
    "#         \"convective_snowfall\",\n",
    "#         \"convective_snowfall_rate_water_equivalent\",\n",
    "#         \"large_scale_snowfall_rate_water_equivalent\",\n",
    "#         \"large_scale_snowfall\",\n",
    "#         \"snow_albedo\",\n",
    "#         \"snow_density\",\n",
    "#         \"snow_depth\",\n",
    "#         \"snow_evaporation\",\n",
    "#         \"snowfall\",\n",
    "#         \"snowmelt\",\n",
    "#         \"temperature_of_snow_layer\",\n",
    "#         \"total_column_snow_water\"\n",
    "#     ]\n",
    "\n",
    "variables = [\n",
    "        \"10m_u_component_of_wind\",\n",
    "        \"10m_v_component_of_wind\",\n",
    "        \"2m_dewpoint_temperature\",\n",
    "        \"2m_temperature\",\n",
    "        \"mean_sea_level_pressure\",\n",
    "        \"surface_pressure\",\n",
    "        \"total_precipitation\",\n",
    "        \"ice_temperature_layer_1\",\n",
    "        \"ice_temperature_layer_2\",\n",
    "        \"ice_temperature_layer_3\",\n",
    "        \"ice_temperature_layer_4\",\n",
    "        \"maximum_2m_temperature_since_previous_post_processing\",\n",
    "        \"minimum_2m_temperature_since_previous_post_processing\",\n",
    "        \"skin_temperature\",\n",
    "        \"100m_u_component_of_wind\",\n",
    "        \"100m_v_component_of_wind\",\n",
    "        \"10m_u_component_of_neutral_wind\",\n",
    "        \"10m_v_component_of_neutral_wind\",\n",
    "        \"10m_wind_gust_since_previous_post_processing\",\n",
    "        \"instantaneous_10m_wind_gust\",\n",
    "        \"cloud_base_height\",\n",
    "        \"high_cloud_cover\",\n",
    "        \"low_cloud_cover\",\n",
    "        \"medium_cloud_cover\",\n",
    "        \"total_cloud_cover\",\n",
    "        \"total_column_cloud_ice_water\",\n",
    "        \"total_column_cloud_liquid_water\",\n",
    "        \"vertical_integral_of_divergence_of_cloud_frozen_water_flux\",\n",
    "        \"vertical_integral_of_divergence_of_cloud_liquid_water_flux\",\n",
    "        \"vertical_integral_of_eastward_cloud_frozen_water_flux\",\n",
    "        \"vertical_integral_of_eastward_cloud_liquid_water_flux\",\n",
    "        \"vertical_integral_of_northward_cloud_frozen_water_flux\",\n",
    "        \"vertical_integral_of_northward_cloud_liquid_water_flux\",\n",
    "        \"convective_precipitation\",\n",
    "        \"convective_rain_rate\",\n",
    "        \"instantaneous_large_scale_surface_precipitation_fraction\",\n",
    "        \"large_scale_rain_rate\",\n",
    "        \"large_scale_precipitation\",\n",
    "        \"large_scale_precipitation_fraction\",\n",
    "        \"maximum_total_precipitation_rate_since_previous_post_processing\",\n",
    "        \"minimum_total_precipitation_rate_since_previous_post_processing\",\n",
    "        \"precipitation_type\",\n",
    "        \"total_column_rain_water\",\n",
    "        \"convective_snowfall\",\n",
    "        \"convective_snowfall_rate_water_equivalent\",\n",
    "        \"large_scale_snowfall_rate_water_equivalent\",\n",
    "        \"large_scale_snowfall\",\n",
    "        \"snow_albedo\",\n",
    "        \"snow_density\",\n",
    "        \"snow_depth\",\n",
    "        \"snow_evaporation\",\n",
    "        \"snowfall\",\n",
    "        \"snowmelt\",\n",
    "        \"temperature_of_snow_layer\",\n",
    "        \"total_column_snow_water\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5dbdc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Data splits already exist under data/era5_data. Skipping split.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x16ab36790>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x16a416390>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x16ab50750>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from src.helper_functions import set_seeds, set_data_splits, create_dataloaders\n",
    "from src.met_transformer.met_utils import WeatherDataset\n",
    "\n",
    "set_seeds(42)\n",
    "\n",
    "splits_path = Path(\"data/era5_data\")\n",
    "weather_csv = Path(\"data/era5_data/era5_data.csv\")\n",
    "weather_df = pd.read_csv(weather_csv, parse_dates=[\"event_date\"])\n",
    "\n",
    "metadata_cols = [\"PEAKID\", \"parent_peakid\", \"event_date\"]\n",
    "X = weather_df.drop(columns=[\"Target\"])\n",
    "y = weather_df[\"Target\"]\n",
    "\n",
    "set_data_splits(X, y, splits_path, seed=42)\n",
    "\n",
    "weather_train_dataloader, weather_val_dataloader, weather_test_dataloader = create_dataloaders(\n",
    "    dataset_class=WeatherDataset,\n",
    "    train_file=splits_path / \"train\" / \"train.csv\",\n",
    "    val_file=splits_path / \"val\" / \"val.csv\",\n",
    "    test_file=splits_path / \"test\" / \"test.csv\",\n",
    "    batch_size=32,\n",
    "    dataset_kwargs={\n",
    "        'target_column': 'Target',\n",
    "        'metadata_cols': metadata_cols,\n",
    "        'continuous_mean_std': None,\n",
    "        'priority_features':  priority_features,\n",
    "        'variables': variables\n",
    "    }\n",
    "\n",
    ")\n",
    "\n",
    "weather_train_dataloader, weather_val_dataloader, weather_test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac830ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "print(len(variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07f69004",
   "metadata": {},
   "outputs": [],
   "source": [
    "offsets= range(0, 8)\n",
    "met_weights_with_offset = {\n",
    "    f\"{feat}_t-{off}\":weight\n",
    "    for feat, weight in met_weights.items()\n",
    "    for off in offsets\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be621029",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.met_transformer.met_model import Stormer\n",
    "from src.tab_transformer.tab_model import SAINT\n",
    "\n",
    "\n",
    "stormer = Stormer(img_size=[128, 256],\n",
    "                  variables=variables,\n",
    "                  met_weights=met_weights_with_offset,\n",
    "                  patch_size=2,\n",
    "                  hidden_size=1024,\n",
    "                  depth=24,\n",
    "                  num_heads=16,\n",
    "                  mlp_ratio=4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046b7233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred: tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], grad_fn=<SliceBackward0>)\n",
      "Its shape: torch.Size([32, 220])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aaronserpilin/anaconda3/envs/Python3_Env/lib/python3.11/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 220])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (220) must match the size of tensor b (32) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m loss_fn = nn.MSELoss().to(device)\n\u001b[32m      5\u001b[39m optimizer = torch.optim.AdamW(stormer.parameters(),lr=\u001b[32m3e-4\u001b[39m, betas=(\u001b[32m0.9\u001b[39m, \u001b[32m0.999\u001b[39m), weight_decay=\u001b[32m1e-2\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstormer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m           \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweather_train_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m           \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m           \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m           \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m           \u001b[49m\u001b[43mlambda_reg\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-3\u001b[39;49m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# val_step = test_step(model=saint,\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m#                      dataloader=weather_val_dataloader,\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m#                      loss_fn=loss_fn,\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m#                      device=device)\u001b[39;00m\n\u001b[32m     19\u001b[39m \n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# val_step\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Extra-Programming-Courses/Pytorch-Projects/DeepSummit/src/met_transformer/met_train.py:51\u001b[39m, in \u001b[36mtrain_step\u001b[39m\u001b[34m(model, dataloader, loss_fn, optimizer, device, lambda_reg)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33my_pred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_pred\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mIts shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_pred.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# Regularization for mask and weights precedence initialization\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m classification_loss = \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m weights = model.embedding.feature_weights\n\u001b[32m     53\u001b[39m reg_loss = lambda_reg * torch.sum(weights * weights)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/Python3_Env/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/Python3_Env/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/Python3_Env/lib/python3.11/site-packages/torch/nn/modules/loss.py:610\u001b[39m, in \u001b[36mMSELoss.forward\u001b[39m\u001b[34m(self, input, target)\u001b[39m\n\u001b[32m    609\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m610\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/Python3_Env/lib/python3.11/site-packages/torch/nn/functional.py:3884\u001b[39m, in \u001b[36mmse_loss\u001b[39m\u001b[34m(input, target, size_average, reduce, reduction, weight)\u001b[39m\n\u001b[32m   3881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3882\u001b[39m     reduction = _Reduction.legacy_get_string(size_average, reduce)\n\u001b[32m-> \u001b[39m\u001b[32m3884\u001b[39m expanded_input, expanded_target = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3886\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3887\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m weight.size() != \u001b[38;5;28minput\u001b[39m.size():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/Python3_Env/lib/python3.11/site-packages/torch/functional.py:76\u001b[39m, in \u001b[36mbroadcast_tensors\u001b[39m\u001b[34m(*tensors)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, *tensors)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (220) must match the size of tensor b (32) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "from src.met_transformer.met_train import train_step, test_step\n",
    "\n",
    "# Hyperparameters pulled from the paper\n",
    "# loss_fn = nn.MSELoss().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(stormer.parameters(),lr=3e-4, betas=(0.9, 0.999), weight_decay=1e-2)\n",
    "\n",
    "train_step(model=stormer,\n",
    "           dataloader=weather_train_dataloader,\n",
    "           loss_fn=loss_fn,\n",
    "           optimizer=optimizer,\n",
    "           device=device,\n",
    "           lambda_reg=1e-3\n",
    ")\n",
    "\n",
    "# val_step = test_step(model=saint,\n",
    "#                      dataloader=weather_val_dataloader,\n",
    "#                      loss_fn=loss_fn,\n",
    "#                      device=device)\n",
    "\n",
    "# val_step"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
